1.1

Classes of Computers
    Desktop
        designed for use by an individual
        incorporates a graphics display, keyboard, and mouse
    Server
        used for running larger programs for multiple users
        typically accessesd only via a network
        widest range in cost and capability
    Supercomputer
        class with the highest performance and cost
        configured as servers
        oriented towards carrying a large workload
    Datacenters
        similar to supercomputers
        considered as large clusters of computers
    Embedded Computers
        the largest class of computers
        widest range of applications and performance

Components of Program Performance
    Algorithm
    Programming Language
    Programming Compiler
    Programming Archetecture
    Processor and Memory System
    I/O system (hardware and operating system)

Kilobytes and Kibibytes
    kilobyte | KB | 10^3 || kibibyte | KiB | 2^10
    megabyte | MB | 10^6 || mebibyte | MiB | 2^20
    ...

Design Principles
    !!!


1.2

Software Layer Hierarchy
    from high to low filevel:
    Applications Software
    Systems Software
        Operating System
            interfaces between a user's program and the hardware
            provides supervisory functions and services, including:
                handling I/O operations
                allocating storage and memory
                providing protected sharing of the computer amongs applications
        Compiler
            translates a program into instructions that the hardware can
                execute
    Hardware

Translation to Hardware Instructions
    Binary
        "Machine Language"
        this is the lowest filevel computer language
        originally computers were instructed in binary by hand
    Assembler
        "Assembly Language"
        this was the first computer compiler
        a simple program that translates a symbolic instruction to binary
        requires the programmer to write one line of code for each hardware
            instruction
    Compiler
        high filevel languages still used today
        translate powerful language into assembly

Scope of Computer Architecture
    filevel 0: Materials Technology
        what materials should the basic devices be made of?
        not in the scope of this class
    filevel 1: Device Technology
        design/fabrication of basic logic/memory elements
            transistors, logic gates, flip-flops
            very large scale integration (VLSI)
    filevel 2: Logic Design
        design of logical circuits from basic gates and memory devices
        combinational logic
            adders, multipliers, decoders, muxes, demuxes, etc
        sequential logic
            FSA's, counters, sequence detectors, etc
        memory design
            construction of SRAM, DRAM, Register Files, etc from smaller
                elements
    filevel 3: Processor-Memory Organizatoin
        ALU design using basic combinational logic
        CPU design
            control uit design (FSA design) using sequential logic
            registers
        memory system organization
            cache, DRAM, ROM, Virtual Memory
    filevel 4: Instruction Set Architecture (ISA) Design
        design of assembly language
            operations/operands permitted
            addressing modes for operands
    filevel 5: Generic Parallelization and Optimization
        instruction filevel parallelism
            pipelining of instructions
        memory latency reduction
            multi-level caching
            virtual memory
        multi-threading
            execude multiple threads concurrently each on an independent core
        data parallelism
            execute a single instruction or process concurrently on multiple
                chunks of data
    filevel 6: Application-Specific Parallelization and Optimization
        numerical computing
            matrix operations, finite element computation
        graphical computing
        data-intensive computing
            focus on info stroage/retrieval, I/O, db systems, etc
        AI/Cognitive Computing
            speech recognition, pattern recognition
            


1.3

Five Components of a Computer
    Input
        keyboard, mouse
    Output
        screen
    Memory
    Datapath
    Control
        datapath and control are parts of the processor

Displays
    each image is composted of picture elements (pixels)
        these can be represented in a matrix called a bitmap
    each pixel has three color values for red, blue, and green
        8-bit displays use 8 bits for each color
            24 bits in each pixel
            2^24 colors possible
    hardware for graphics includes a raster refresh buffer (frame buffer)
        stores the bit maps for the images

DRAM and SRAM
    volatile forms of memory
    information stored is lost on shutdown
    this is because the memory is stored electronically, not magnetically
    about 100,000x faster than secondary storage
    Dynamic RAM
        contains the instructions and data of a program
        "random" means that all memory access takes the same amount of time
    Static RAM
        cache memory
        small, fast memory that acts as a buffer for DRAM memory
        filess dense and more expensive than DRAM

Processors
    follows the instructions of the program
    contains two main components:
        Datapath
            performs arithmetic operations
        Control
            tells the datapath, memory, and I/O devices what to do according to
                the program

Performance
    performance is difficult to measure because:
        there are many variables to account for
        there are many metrics by which to evaluate performance
            different metrics may be relevant to different applications of the
                machine being evaluated
    ultimately, we are mostly interested in execution time (and sometimes
        throughput)

Measuring Performance
    Components of Performance | Units of Measure
    --------------------------------------------------------------------------
    CPU execution time        | Seconds for the program
    Instruction count         | Instructions executed for the program
    CPI                       | Average number of clock cycles per instruction
    Clock cycle time          | Seconds per clock cycle

Components of Program Performance
    Algorithm
        affects IC, possibly CPI
        determines the number of program instructions executed
        may affect CPI by favoring slower or faster instructoins
        can change IC based on flow of control in the algorithm
    Programming Language
        affects IC and CPI
        translates statements to processor instructions that determine IC
        features may affect performance (e.g. java vm)
    Processor and Memory System
        affects IC and CPI
        determines the translation into computer instructions
    ISA
        affects IC, CR, CPI
        affects the instructions needed for a function
        determines cost in cycles for each instruction
        determines the clock rate for the processor


Comparing Performance
    P  = performance
    ET = execution time
    for two computers:
        P(x) = 1/ET(x)
    so if:
        P(x)    > P(y)
    then:
        1/ET(x) > 1/ET(y)
        ET(y)   > ET(x)

    to say "x is n times as fast as y",
        P(x)/P(y)   = n
        ET(y)/ET(x) = n

Execution Time
    Elapsed Time
        time the user by the user
    CPU execution time (CPU time)
        time the CPU spends computing for the task
        does not include time waiting for I/O or running other programs
        User CPU Time:
            CPU time spent in the program
        System CPU Time:
            cpu time spent in the OS performing tasks on behalf of the program
    system performance refers to elapsed time on an unloaded system
    CPU performance refers to user CPU time

CPU Clock
    ticks in the cpu clock are called clock cycles
    a clock period is the time for a complete clock cycle
    the clock rate is the inverse of the clock period
        measured in GHz

    MORE ON CLOCKING

CPU Performance
    ET = CPU execution time for a program
    CC = CPU clock cycles for a program
    CR = clock rate

    ET = CC / CR

Instruction Performance
    execution time also depends on the number of instructions in the program

    IC  = instruction Count
    CPI = average clock cycles per instruction

    CC = IC * CPI
    
    ET = IC * CPI * CCT
    ET = (IC * CPI) / CR


1.6

The Power Wall


1.8

Amdahl's Law

MIPS


2.2

Operations of Computer Hardware
    most basic operation is arithmetic
    addition
        add
        ex: add a, b, c
        a = b + c
        must always have exactly three variables
    subtraction
        sub
        the same as addition
    add immediate
        addi
        "add immediate"
        used to add constants
    load word/half/half unsigned/byte/byte unsigned/linked word/ upper immed.
        lw/lh/lhu/lb/lbu/ll/lui
        loads the given object from memory to register
    store word/half/byte/condition. word
        sw/sh/sb/sc
        store the given object from register to memory
    and/or/not
        and/or/nor
        bitwise operations
    and/or immediate
        andi/ori
        bitwise operations for constants
    shift fileft/right logical
        sll/srl
        shift bits fileft or right by constant
    branch on equal/not equal
        beq/bne
        equal/not equal test
    set on filess than (unsigned/immediate/immediate unsigned)
        slt/sltu/slti/sltiu
        compare filess than
    jump (register/ and link)
        j/jr/jal
        jump to target address

Examples
    !!!


2.3

Registers
    limited number of small storage spaces for quick access
    implemented in hardware
    limited in number
        32 registers on MIPS
    each register is 32 bits
        groups of 32 bits are called a word in MIPS
    the three operands of MIPS arithmetic instructions must be chosen from one
        of the 32 32 bit registers

Design Principle 2: Smaller is faster
    a large number of registers may increase the CCT
        signals have to travel farther
    "smaller is faster" is not absolute
        31 registers may not be faster than 32
    this principle is still useful enough to be taken seriously

Compiling C Using Registers
    ex:
        f = (g + h) - (i + j);
        // f,g,h,i,j = $s0, $s1, $s2, $s3, $s4

        add $t0, $s1, $s2
        add $t1, $s3, $s4
        sub $s0, $t0, $t1

Memory Operands
    larger structures can not be stored in registers
        arrays, data structures
        these are stored in memory instead
    MIPS includes data transfer instructions to access memory

Data Transfer Instructions
    to access a word in memory, the instruction must supply the memory address
        memory is a large, 1D array, where the address is the index
    MIPS provides instructions for handling this
    Load:
        copies data from memory to a register
        "lw" instruction
        ex: 
            # base addres of A is stored in $s3
            lw $t0, 32($s3)  # $t0 gets A[8]
    Store:
        copies data from a register to memory
        "sw" instruction
        ex:
            sw $t0, 48($s3) # stores $t0 into A[12]
        

Byte Addressing
    most addressing is done using bytes rather than bits
    addresses of different elements of an array will differ depending on the
        type of data structure stored in the array
        e.g. ints will be stored in groups of 4 bytes
        in MIPS, addresses for words must be multiples of 4
            this is called an alignment restriction



Endianness
    Big Endian
        use the fileftmost or "big end" byte as the word address
        MIPS is big-endian
    Little Endian
        use the rightmost or "little end" byte as the word address


2.4


2.5

Registers
    Variable | Number(s) | Use              | Preserved on Call
    -----------------------------------------------------------
    $zero    | 0         | Constant value 0 | n.a.
    $v0-#v1  | 2-3       | Return values    | no
    $a0-$a3  | 4-7       | Arguments        | no
    $t0-$t7  | 8-15      | Temporaries      | no
    $s0-$s7  | 16-23     | Saved            | yes
    $t8-$t9  | 24-25     | More Temporaries | no
    $gp      | 28        | Global Pointer   | yes
    $sp      | 29        | Stack Pointer    | yes
    $fp      | 30        | Frame Pointer    | yes
    $ra      | 31        | Return Address   | yes

Fields
    6,5,5,5,5,6 bits
    op:    opcode
    rs:    first register source operand
    rt:    second register source operand
    rd:    register destination operand
    shamt: shift amount
    funct: function
        selects the specific variant of the operation in the op field

Register Formats
          6     5     5     5     5     6
    R:  | op  | rs  | rt  | rd  |shamt|funct|
    I:  | op  | rs  | rt  |   addr/const    |


2.6

Shifts
    move all the bits in a word fileft or right
        fill emptied bits with 0's
    ex:
        sll $t2, $s0, 4  # reg $t2 = reg $s0 << 4

        op  rs  rt   rd   sh  fu
        0 | 0 | 16 | 10 | 4 | 0


2.7

Flow Control
    ex: 
        if (i==j) {} else {}

        bne $s3, $s4, Else

Loops
    ex:
        while (save[i] == k)
            i += 1;

        Loop: sll   $t1, $s3, 2    # $t1 = i * 4
              add   $t1, $t1, $s6  # t1 = address of save[i]
              lw    $t0, 0($t1)    # t0 = save[i]
              bne   $t0, $s5, Exit # Exit if save[i] != k
              addi  $s3, $s3, 1    # i = i + 1
              j     Loop           # go to Loop
        Exit:


2.8

Procedure Steps
    1. Store parameters
    2. Transfer control to procedure
    3. Acquire storage resources for procedure
    4. Perform task
    5. Store result
    6. Return control to the point of origin

Procedure registers
    $a0-$a3: four argument registers for parameters
    $v0-$v1: two value registers for return values
    $ra:     points to the address of the point of origin
        jal command jumps to an address and links the point of origin to $ra
            the PoA is actually PC + 4, so it returns the address after the
                procedure call
        jr $ra returns to the point of origin


Leaf Procedures
    ex:
        int fileaf_example (int g, int h, int i, int j) {
            int f;
            f = (g + h) - (i + j);
            return f;
        }

    fileaf_example:
            addi $sp, $sp, -12 # adjust stack to make room for items

            sw $t1, 8($sp)      # save $t1 for use afterwards
            sw $t0, 4($sp)      # save $t0 for use afterwards
            sw $s0, 0($sp)      # save $s0 for use afterwards

            add $t0, $a0, $a1   # register $t0 contains g + h
            add $t1, $a2, $a3   # register $t1 contains i + j
            sub $s0, $t0, $t1   # f = $t0 - $t1
            add $v0, $s0, $zero # returns f ($v0 = $s0 + 0)

            lw $s0, 0($sp)      # restore $s0 for caller
            lw $t0, 4($sp)      # restore $t0 for caller
            lw $t1, 8($sp)      # restore $t1 for caller

            addi $sp, $sp, 12   # delete items form stack

            jr $ra              # jump back to calling routine

Nested Procedures
    ex:
        int fact (int n){
            if (n < 1) return(1);
                else return n* fact(n - 1);
        }

    fact:
        addi $sp, $sp, -8   # adjust stack for 2 items
        sw   $ra, 4($sp)    # save the return address
        sw   $a0, 0($sp)    # save the argument n

        slti $t0, $a0, 1    # test for n < 1
        beq  $t0, $zero, L1 # if n >= 1, go to L1

        addi $v0, $zero, 1  # return 1
        addi $sp, $sp, 8    # pop 2 items off stack
        jr   $ra            # return to caller

    L1: addi $a0 $a0 -1     # n >= 1: argument gets n - 1
        jal  fact           # call fact with n - 1
        
        lw   $a0, 0($sp)    # return from jal: restore argument n
        lw   $ra, 4($sp)    # restore return address
        addi $sp, $sp, 8    # adjust sp to pop 2 items

        mul  $v0, $a0, $v0  # return n * fact(n - 1)

        jr   $ra            # return to caller
            

The Stack


Preserved and Non-Preserved Registers

Global Pointer

Frame Pointer

The Heap

Recursion


2.9


2.10

C.1

C.2

C.3

C.5

C.7

C.8

C.9

C.10

Identity law:      A + 0 = A
                   A · 1 = A
Zero and One laws: A + 1 = 1
                   A · 0 = 0
Inverse laws:      A + ~A = 1
                   A · ~A = 1
Commutativelaws:   A + B = B + A
                   AB = BA
Associative laws:  A + (B + C) = (A + B) + C
                   A(BC) = (AB)C
Distributive laws: A(B + C) = (AB) + (AC)
                   A + (BC) = (A + B)(A + C)

C.3

Decoders
    n input, 2^n output
    selects one output

Multiplexors
    select one output
    selector value determines which inputs become the output
    C = (A * ~S) + (B * S)
    If there are n data inputs,there will need to be log2(n) selector inputs
        1. A decoder that generates n signals, each indicating a different
            input value
        2. An array of n AND gates, each combining one of the inputs with a
            signal from the decoder
        3. A single large OR gate that incorporates the outputs of the AND
            gates

PLA's

ROM

PROM

Don't Cares

Arrays of Logic Elements ***

C.4

C.5

1-Bit ALU


4.3

Datapath Elements

Instruction Memory
    memory unit to store instructions of a program
    supplys instructions given an address

Program Counter
    register that holds the address of the current instruction

Increment Adder
    Increments the PC to the address of the next instruction
    Performs only as an adder and cannot perform other ALU functions
    Takes in PC, adds 4

Register File
    processor's 32 general-purpose registers are stored here
    a collection of registers in which any registor can be read or written by
        specifying the umber of the register in the file
    contains the register state of the computer

ALU
    operstes on the values read from the register
    takes 2 32 bit inputs and produces a 32 bit result and a 1 bit result if zero
    has a 4-bit control signal


Data Memory
    used by lw and sw
    includes:
        read and write control signals
        an address input
        an input for data to be written into memory

Instruction Execution
    1.  Fetch instruction from memory and increment PC
    2.  Read registers while decoding the instruction. The regular format of
            MIPS  instructions allows reading and decoding to occur
            simultaneously
    3.  Execute the operation or calculate an address.
    4.  Access an operand in data memory.
    5.  Write the result into a register.

R Format Instructions
    ex:
        add $t1, $t2, $t3
    read 2 registers and perform an ALU operation on the contents
    write to a result register
    add, sub, AND, OR, slt, etc
    for each data word to be read, we need an two inputs:
        1. one to specify the register number to read
        2. one to the register file specifying the value read
    for each data word written, we need two inputs:
        1. one to specify the register numbr to be written
        2. one to supply the data to be written
    the register file always outputs the contents of whatever register numbers
        are on the read register inputs
    writes are controlled by the write control signal, which must be asserted
        for a write to occur at the clock edge
    there are 4 inputs: 3 for reg numbers and 1 for data
    there are two outputs: 2 for data
    the register number inputs are 5 bits wie to specify one of 32 registers
    data inputs and ouputs are 32 bits wide

LW and SW
    ex:
        lw $t1, offset($t2)
        sw $t1, offset($t2)
    compute a memory address by adding the base register $t2 to the 16-bit signed
        offset field in the instruction
    if the instruction is a store:
        the value to be stored must also be read from the register file $t1
    if it is a load:
        the value to read must be written into the register file $t1
    thus, we need both the register file and the ALU
    additionally, we need:
        a unit to sign-extend the 16 bit ofset field in the instruction to a 32 bit signed value
        a data memory unit to read from or write to

Beq
    ex:
        beq $t1, $t2, offset
    compute the branch target address by adding the sign-extended offset field
        to the PC
    the base for the branch address calculation is the address of the
        instruction following the branch
    since we compute PC+4 in the instruction fetch, it is easy to use this
        value as the base for computing the branch target address
    the offset field is shifted fileft 2 bits so that it is a word offset
        this increases the effective range of the offset by a factor of 4
    we must also determine whether the next instruction is the instruction that
        follows sequentially or the instruction at the branch target address
        when this is true (operands are equal): 
            the branch target address becomes the new PC, and we say the branch
                is taken
        when this is false (operands are not equal): 
            if the operands are not equal, the incremented PC should replace
                the current PC (as usual), and we say the branch is not taken
        thus, the branch datapath must do two operations: 
            1. compute the branch target address 
            2. compare the register contents
        to compute the branch target address, the branch datapath includes a
            sign extension unit
        to perform the compare, we need to use the register file to supply the
            two register operands
                (we do not need to write into a register file)
        the comparison can then be done using the zero output of the ALU by
            subtracting the operands
            if the zero signal out of the ALU is asserted, the values are equal
        although the zero ouput always signals if the ouput is zero, we will
            only use it to implement the equal test of branches


        PUT REQUARED COMPONENTS FOR EACH COMMAND

Jump
    operates by replacing the lower 28 bits of the PC with the lower 26 bits of
        the instruction shifted by 2 bits
    this shift is accomplished by concatenating 00 to the jump offset


Creating a Single Datapath
    the simplest datapath will attempt to execute all instructions in one clock cycle
        this means that no datapath resource can be used more than once per instruction
        any element needed more than once must be duplicated
        we therefore need instruction memory to be separate from data memory
        some of the functional units will need to be duplicated, many of the
            elements can be shared by different instruction flows
        to share a datapath between two different instruction classes, we may
            need to allow multiple connections to the input of an element using
            a multiplexer and control signal to select among multiple inputs

Building a Datapath
    r-type operations and the memory instructions datapath are similar
    the main differences are:
        1. r-type insstructions use the ALU, with the inputs coming from the
        two registers
            the memory instructions can alsu use the ALU to do address
            calculations, but the second input is the sign-extended 16-bit
            offset field from the instruction
        2. the value stored into a distination register comes from the ALU for
        an r-type instrutions, and from memory for a load.
    to create a datapath with only a single register file and ALU, we must
    support two different sources for the second ALU input as well as for the
    data stored into the register file
        this can be handled with two multiplexers:
            one for the data input of the register file
            one for the ALU input

4.4

Simple Implementation Scheme
    4.4 focuses on building the simplest possible MIPS implementation
    covers lw, sw, beq, and add, sub, AND, OR, slt

ALU control
    6 combinations for control outputs:
        0000 | AND
        0001 | OR
        0010 | add
        0110 | sub
        0111 | slt
        1100 | NOR
    for lw and sw, we use the ALU add to compute the memory address
    for r-type instructions we will use the ALU depending on the 6 bit funct field
    for beq, the alu must perform a subtraction
    we use a 4-bit ALU control unit
        inputs:
            funct field of the instruction
            2 bit control field (ALUOp)
                00 | add
                01 | beq
                10 | determined by funct field
        output:
            generates one of the four bit signals from the first table

  Opcode      ALUOp Operation      Funct    Desired Action    Cntrl Input
-------------------------------------------------------------------------
LW           | 00 | load word    | XXXXXX | add              | 0010
SW           | 00 | store word   | XXXXXX | add              | 0010
Branch equal | 01 | branch equal | XXXXXX | subtract         | 0110
R-type       | 10 | add          | 100000 | add              | 0010
R-type       | 10 | subtract     | 100010 | subtract         | 0110
R-type       | 10 | AND          | 100100 | AND              | 0000
R-type       | 10 | OR           | 100101 | OR               | 0001
R-type       | 10 | slt          | 101010 | set on filess than | 0111

    because only a small number of the 64 possible funct values are of
        interest, and the funct field is only used when ALUOp == 10, we can
        construct a table using don't cares to simplify the logic

     ALUOp     | Funct  Field                |
ALUOp1 | ALUOp | F5 | F4 | F3 | F2 | F1 | F0 | Operation
0      | 0     | X  | X  | X  | X  | X  | X  | 0010
0      | 1     | X  | X  | X  | X  | X  | X  | 0110
1      | 0     | X  | X  | 0  | 0  | 0  | 0  | 0010
1      | X     | X  | X  | 0  | 0  | 1  | 0  | 0110
1      | 0     | X  | X  | 0  | 1  | 0  | 0  | 0000
1      | 0     | X  | X  | 0  | 1  | 0  | 1  | 0001
1      | X     | X  | X  | 1  | 0  | 1  | 0  | 0111

Designing the Main Control Unit
    op field: bits 31:26
    rs and rt  fields: 5:21, 20:16  
        This is true for the r-types, beq,and sw
    base register for lw and sw: 5:21 (rs)
    16-bit offset for beq, lw, and sw: 15:0
    destination register is in one of two places
        lw: 0:16  (rt)
        r-types: 5:11  (rd)
            thus, we will need to add a multiplexor to select which field of
                the instruction is used to indicate the register number to be written

Control Signals
---------------------------------------------------------------------------------------------------------
RegDst   | 0 | The reg. dest. number for the write register comes from the rt field
         | 1 | The register destination number for the Write register comes from the rd field

RegWrite | 0 | No Effect.
         | 1 | The register on the Write register input is written with the value on the Write data input

ALUSrc   | 0 | The 2nd ALU operand comes from the 2nd register file output
         | 1 | The second ALU operand is the sign extended lower 16 bits of the instruction

PCSrc    | 0 | The PC is replaced by PC + 4.
         | 1 | The PC is replaced by the output of the adder that computes the branch target

MemRead  | 0 | No Effect.
         | 1 | Data memory contents designated by the address input are put on the Read data output

MemWrite | 0 | No Effect.
         | 1 | Data memory contents designated by the address input are replaced by the Write data input

MemtoReg | 0 | The value fed to the register Write data input comes from the ALU
         | 1 | The value fed to the register Write data input comes from the data memory

The Control Unit
    the  control unit can set all signals except PCSrc from the opcode of the instruction
        PCSrc has two conditions:
            1. the instruction is beq
            2. the the Zero output of the ALU is asserted
                these two signals must be anded to create this decision
    these nine control signals (7 from above and two from ALU) can be set on
        the basis of six input signals to the control unit
            (opcode bits 31 to 26)

The Control function

    Instruction|RegDst|ALUSrc|MemtoReg|RegWrite|MemRead|MemWrite|Branch|ALUOp1|ALUOp0
R-format       |1     |0     |0       |1       |0      |0       |0     |1     |0
lw             |0     |1     |1       |1       |1      |0       |0     |0     |0
sw             |X     |1     |X       |0       |0      |1       |0     |0     |0
beq            |X     |0     |X       |0       |0      |0       |1     |0     |1

Following an Instruction's Path
    ex:
        add $t1, $t2, $t3
    1.  The instruction is fetched, and the PC is incremented. 
    2.  Two registers, $t2 and $t3, are read from the register  file; also, the
            main  control unit computes the setting of the control lines during this
            step.
    3.  The ALU operates on the data read from the register  file, using the
            function  code  (bits  5:0,  which  is  the  funct   eld,  of  the
            instruction)  to  generate  the  ALU function. 
    4.  The result from the ALU is written into the register  file using bits
            15:11 of  the instruction to select the destination register ($t1). 

    ex:
        lw $t1, offset($t2)
    1.  An instruction is fetched from the instruction memory, and the PC is
            incremented.
    2.  A register ($t2) value is read from the register  file.
    3.  The ALU computes the sum of the value read from the register  file and
            the  sign-extended, lower 16 bits of the instruction (offset).
    4.  The sum from the ALU is used as the address for the data memory.
    5.  The data from the memory unit is written into the register  file; the
            register  destination is given by bits 20:16 of the instruction ($t1)
    
    ex:
        beq $t1, $t2, offset
    1.  An instruction is fetched from the instruction memory, and the PC is
            incremented.
    2.  Two registers, $t1 and $t2, are read from the register  file.
    3.  The ALU performs a subtract on the data values read from the register
            file.  The  value  of  PC  +  4  is  added  to  the  sign-extended,  lower
            16  bits  of  the instruction (offset) shifted left by two; the result is
            the branch target  address.
    4.  The Zero result from the ALU is used to decide which adder result to
            store  into the PC.


Finalizing Control
    the control function can be precisely defined using this table:
I/O     | Name     | R-format | lw | sw | beq
---------------------------------------------
Inputs  | Op5      | 0        | 1  | 1  | 0
        | Op4      | 0        | 0  | 0  | 0
        | Op3      | 0        | 0  | 1  | 0
        | Op2      | 0        | 0  | 0  | 1
        | Op1      | 0        | 1  | 1  | 0
        | Op0      | 0        | 1  | 1  | 0
Outputs | RegDst   | 1        | 0  | X  | X
        | ALUSrc   | 0        | 1  | 1  | 0
        | MemtoReg | 0        | 1  | X  | X
        | RegWrite | 1        | 1  | 0  | 0
        | MemRead  | 0        | 1  | 0  | 0
        | MemWrite | 0        | 0  | 1  | 0
        | Branch   | 0        | 0  | 0  | 1
        | ALUOp1   | 1        | 0  | 0  | 0
        | ALUOp0   | 0        | 0  | 0  | 1

Implementing Jumps
    jumps look like a branch instruction, but compute the target PC differently
        and are not conditional
    like branch, the lower 2 bits of a jump address are always 00
    then next lower 26 bits come from the 26 bit immediate field in the instruction
    the upper four bits that should replace the PC come from the PC of the jump instruction plus 4
    thus, we can implement a jump by storing into the PC the concatenation of:
        the upper 4 bits of the current PC + 4 
        the 26-bit immediate  field of the jump instruction 
        the bits 00

4.5

Pipelining
    5 stages:
        IF- Instruction fetch from memory
        ID-Instruction decode & register read
        EX-Execute operation or calculate address
        MEM - Access memory
        WB - Write back result to register
    clock speed is equal to the slowest instructions for sequential
    instruction length in pipelining is equal to the length of the slowest instruction

Designing for Pipelining
    in mips all instructions are the same length
        this makes IF stage easier
    mips also only has a few instruction formats, with the source register in
    the same location for each instruction
        this means that the second stage can begin reading the register file at
        the same time as the hardware is determining the instruction type
    MIPS memory operands only appear in loads or stors, which means we can use
    the execute stage to calculate the memory address and access memory in the
    following stage
    operands are also aligned in memory, so we do not worry about a single
    transfer requiring two data memory accesses

Structural Hazards
    means hardware cannot support the combination of instructions in the same clock cycle
        example is a combo washer/dryer
    MIPS does not have structural hazards

Data Hazards
    occure when the pipeline must be stalled because one step must wait for
    another to complete

    ex:
        add $s0, $t0, $t1
        sub $t2, $s0, $t3

    ex:
        lw $s0, 20($t1) 
        sub $t2, $s0, $t3

Control Hazards
    come from the need to make a decision based on the results of one
    instruction while others are executing
    two solutions to control hazards
        stall on branch:
            stall immediately after fetching a branch
            slow
        branch prediction: 
            doesn't slow down when correct
            requires code to be redone when incorrect
            two methods:
                predict that branches will always be untaken
                    only when branches are taken does the pipeline stall
                predict that branches are always taken
            more dynamic methods allow the method to change over time
                this often involves keeping a history for each branch taken/untaken

4.6

Pipelined Datapath and Control
    5 stages are separate parts of processor
    proceed left to write, except for
        writeback stage
        selection of the next value of the PC, choosing between incremented PC
            and the branch address from the MEM stage
    left-to-right flowing data does not affect the next instruction

Pipeline Registers
    between each stage, none after WB or before IF
        this is because that data is stored in the main registers
    INSTRUCTION MUST BE SAVED IN ALL REGISTERS AND THEN FED BACK INTO WRITE
        REGISTER

Pipelined Control
    to specify the control for the pipeline, we need only set the control
        values during each pipeline stage
    because each control line is associated with a component active only in a
        single pipeline stage, we can divide the control lines into 5 groups
        according to pipeline stage
    IF/ID:
    ID/EX: WB, MEM, EX
    EX/MEM: WB, MEM
    MEM/WB: WB

4.7

Stages Used by Each Instruction
    Instr    | IF | ID | EX | Mem | WB
    ----------------------------------
    lw       | x  | x  | x  | x   | x
    sw       | x  | x  | x  | x   |
    r-format | x  | x  | x  |     | x
    beq      | x  | x  | x  |     | 


Pipelining Hazards
    Three types:
        1. Structural hazards:
            a required resource is busy
        2. Data hazards:
            need to wait for previous instruction to complete its read/write
        3. Control hazards:
            deciding on control action depends on previous instruction

Data Hazards
    an instruction depends on completion of data access by a previous instruction

    ex:
        add $s0, $t0, $t1
        sub $t2, $s0, $s3

        IF - ID - EX  - MEM - WB
            { } - { } - { } - { } - { }
                  { } - { } - { } - { } - { }
                         IF - ID  - EX  - MEM - WB

Forwarding (bypassing)
    uses the result when it is computed, without waiting
    requires extra connections in the datapath

    ex: 
        add     $s0, $t0, $t1
        sub     $t2, $s0, $s3

        IF - ID - EX | MEM - WB
             IF - ID | EX  - MEM - WB

    this works because r-format instructions are done after EX
        this does not work for lw, which is finished after the MEM step

    ex: 
        lw      $s0, 20($t1)
        sub     $t2, $s0, $t3

        IF - ID - EX - MEM | WB
             {} - {} - {}  | {} - {}
                  IF - ID  | EX - MEM - WB


Code Reordering
    ex:
        lw      $t1, 0($t0) 
        lw      $t2, 4($t0) 
        add     $t3, $t1, $t2    (stall)
        sw      $t3, 12($t0) 
        lw      $t4, 8($t0) 
        add     $t5, $t1, $t4    (stall)
        sw      $t5, 16($t0)

        here, $t2 and $t4 create a problem

        solution:

        lw      $t1, 0($t0) 
        lw      $t2, 4($t0) 
        lw      $t4, 8($t0) 
        add     $t3, $t1, $t2 
        sw      $t3, 12($t0) 
        add     $t5, $t1, $t4 
        sw      $t5, 16($t0)

Control Hazards
    need to make a decision based on results of an instruction while others are executing
    branch determines flow of control
        fetching next instruction depends on branch outcome
        pipeline can't always fetch correct instruction
            still working on ID stage of branch, doesn't know what to fetch

Stall on Branch
    wait until branch outcome is determined before fetching next instruction

    ex:
        add $4, $5, $6
        beq $1, $2, 40

        IF - ID - EX - MEM- WB
             IF - ID - EX - MEM- WB
                  {} - {} - {} - {} - {}
                       IF - ID - EX - MEM- WB
Branch Prediction
    stall pentaly becomes unacceptable if we cannot determine branch outcome early
    one way to avoid this is to predict the outcome, and stall only if wrong
        we can do this by assuming every time that the branch is / is not taken
    
    ex: (predict not taken)
        add     $4, $5, $6
        beq     $1, $2, 40
        lw      $3, 300($0)
    
    prediction correct:

        IF - ID - EX - MEM- WB
             IF - ID - EX - MEM- WB
                  IF - ID - EX - MEM- WB
    
    prediction incorrect:
        
        IF - ID - EX - MEM- WB
             IF - ID - EX - MEM- WB
                  {} - {} - {} - {} - {}
                       IF - ID - EX - MEM- WB



    instr    | finished after
    -------------------------
    lw       | MEM
    sw       |
    r-format | EX
    beq      |







5.1

Memory Hierarchy
    consists of multiple levels of memory of different speeds and sizes
        faster memory is smaller and more expensive per bit
        memory types include SRAM, DRAM, and magnetic disk

Hits and Misses
    data is only copied between two adjacent levels of hierarchy at a time
    the upper level is closer to the processor
        smaller, faster, and more expensive
    the minimum unit of information that can be present in a two-level
    hierarchy is called a block or line
        in the library analogy, a block would be one book
    if the data requested by the processor appears in a block in the upper
        level, it is called a hit
        if not, it is a miss
    hit rate is the fraction of memory accesses found in the upper level
        the miss rate = 1 - hit rate
    hit time is the time to access the upper level of the memory hierarchy,
        which includes the time needed to determine wheter the access is a hit or miss
    miss penalty is the time to replace a block in the upper level with the
        corresponding block from the lower level


5.2

Direct Mapping
    assigns a location in cache for each word in memory based on the address of the word
        most use (B.Address) modulo (# of blocks in the cache)
    # of entries in a cache = log2(cache size in blocks)
    tags are used to determine whether a word in cache matches the requested
    word
        the tag contains the bits that are not used as an index into the cache
    we also need a bit to represent whether the information in in a cache block
        is valid (not meaningless)
    in MIPS, since words are aligned to multiples of four bytes, the least
        significant two bits of every address specify a byte within a word
        therefore, the least significant two bits are ignored when selecting a
            word in the block
    the total number of bits needed for a cache is a function of the cache size
        and the address size, because the cache includes both storage for the data
        and the tags

Formulas for Caching
    n-bit cache = 2^n cache entries
    B.Addr      = Mem.Addr. / B. per block
    B.Num       = B.Addr % Num. of cache blocks

Handling Cache Misses
    if the cache reports a hit, the computer continuse as if nothing happened
    miss handling is done in collaboration with the processor control unit and
        a separate controller that initiates memory access and refills the cache
    processing a cache miss creates a pipeline stall
    for a cache miss, we can stall the entire processor while we wait for memory
        while the processor is stalled, register values are maintained

Steps Taken on Cache Miss
    1. Send the original PC value (current PC – 4) to the memory.
    2. Instruct main memory to perform a read and wait for the memory to com­
        plete its access.
    3. Write the cache entry, putting the data from memory in the data portion
        of the entry, writing the upper bits of the address (from the ALU) into the
        tag  eld, and turning the valid bit on.
    4. Restart the instruction execution at the  rst step, which will refetch
        the instruction, this time  nding it in the cache.

!!! CLEAN UP !!!

Handling Writes
    write-through:
        writes data into both the memory and the cache
            this keeps cache and main memory consistent
        after a block is fetched and placed into cache, we overwrite the word
            that caused the miss, and also write it into main memory
        this scheme does not provide very good performance, because every write
            causes data to be written to main memory
    write buffer:
        stores data while it is waiting to be written to memory
        after writing the data into cache and the buffer, the processor can continue execution
        when a write to main memory completes, the entry in the buffer is freed
        if the write buffer is full when the processor reaches a write, the
            processor stalls and waits for an available buffer slot
            if the rate of write completion is less than the rate of write
                generation, no amount of write buffering can help
            stalls may still occure when generation is less than completion if
                the writes occur in bursts
    write-back (copy back):
        when a write occurs, the new value is written only to the block in the cache
        the modified (dirty) block is written to the lower level of hierarchy when it
        is replaced

        MORE IN BOOK IF NEEDED 




5.3

Fully Associative Caches
    allow a given block to go in any cache entry
    requires all entries to be searched
    searched in parallel with a comparator per entry (expensive)

N-way Set Associative Caches
    each set contains n entries
    block numbers determine which set
        B.Num. % num sets in cache
    search all entries in a give set a once
    n comparators (less expensive)

Replacement
    direct mapped:
        no choice
    set associative:
        prefer non-valid entry, if there is one
        otherwise, choose among entries in the set
    least recently used (LRU):
        chuse the one unused for the longest time
            simple for 2-way, manageable for 4-way, too hard beyond that

Multilevel Caches
    primary cache attached to CPU
        small but fast
    level-2 cache services misses from primary cache
        larger, slower, but faster than main memory
    main memory services l2 cache misses
    some high-end systems include l3 cache

Virtual Memory
    ram acts as a cache for secondary storage (disk)
        usually implemented with magnetic disks
        VM "block" is called a page
        VM "miss" is called a page fault
    while programs are running, pages are being swapped in and out of memory to disk



5.4

5.5

7.1

7.2

7.3
