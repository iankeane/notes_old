Thu Aug 11 08:02:53 EDT 2016
----------------------------

Office Hours
    416 Boyd
    Mon:  3:30PM- 4:30PM
    Tue:  9:30AM-10:30AM
    Wed: 10:00AM-11:00AM
    Thu:  9:30AM-10:30AM
    706-340-4707


Textbook
    Computer Graphics with OpenGL (Hearn, Baker, Carithers)

Graphics vs Image Processing
    significant overlap
        signal processing is similar
        these three subjects fall under the category of "imaging science"
    typical graphics package:
        input is some sort of description
            describes the image to be drawn
        output is an artificially created image
    typical image processing package:
        input is a picture
        output is a description (of a picture)
    so, a graphics package and IP package are the inverse of each other

Analog vs Digital Images
    Analog:
        precise and accurate
            absolutely "correct"
        an Analog signal will degrade during transfer/transportation
            ex: using a copier to copy an image over and over again
    Digital:
        approximate
            "kind of correct", not precise
        a digital signal will degrade much more slowly than analog
            uses a corrective mechanism to counter energy loss
                this involves rounding values that are off by small amounts
                thus the signal is exact after transfer
                (correction is implemented at the circuit level)
    conversion from analog to digital signals:
        single signal is continuous while analog
        the signal is divided into small chunks during conversion, rounded
            this is similar to estimation for a curve using taylor expansion
            the final picture is in discrete digits

Discrete vs Continuous Video
    true analog video would have infinite fps
        at one trillion fps, you would be able to see light moving
            trillion fps video exists
            creates storage issues
            also creates copying issues
                copying is the most expensive computer operation

Performance and Video
    high performance computing is pushed by the image processing community
        due to the limitation of the speed of light, a display with billions of
            pixels is not possible on one processor

Applications of Computer Graphics
    any computer's front end is a graphics package
    computer games
    simulators
    molecular graphics
    CAD (computer aided design)

Displaying a Line
    lines do not exist (no thickness)
    computer decides which pixels need to be activated to give the impression
        of a geometric shape
    drawing a line is the most important function of a graphics package

Homework:
    google applications of computer graphics
    google one trillion fps video


Tue Aug 16 08:02:10 EDT 2016
----------------------------

Processor Performance
    there are over a hundred miles of path in an average processor
    smaller processors are faster and use less energy
        this is due to reduced distance
        processor shrinking can be done through photographic technology

Parallel Processing
    adding processors to increase performance can circumvent the issue of
        overheating in denser processors
    each neuron in the brain is a processor
        as humans age, they use neurons
        connectivity between neurons is more responsible for brainpower than
            the number of neurons
        the brain, as an adaptive system, can become more powerful by thinking
        the best possible connectivity would be each neuron being directly
            connected to every other neuron
            evolution does not allow this because each neuron would need n
                connections, where n is the number of total connections
            this would make the brain the size of a house
        we have the same optimization issues with parallel processors

CRT Technology
    electron beam shoots through a series of plates before being projected onto
        the glass screen
        first pair of plates are the focusing plates (very small aperture)
        second pair are horizontal deflection plates
        third pair are vertical deflection plates
    the beam hits a layer of chemical behind the screen
        this causes the point to emit light
    two types of chemical:
        1. short-persistent phosphor
            very short emission
            all animation systems must be short persistent
        2. 2. long-persistent phosphor
            has to be specifically deactivated
            to erase a full screen of LPP, even with today's technology, takes
                half a second
    all modern laptops are short-persistent
        screen is made up of pixels
            the entire array of pixels is called the raster
            in this example, each pixel can be black white or grey

Graphics Display Options
    Random Scan Display Device
        naturally a line drawing display device
        refresh system
            to draw a square, the beam of light moves in a square to activate the
                phosphor in the shape of a square
    RSDD's can be huge without increasing processing power too much

Levels of Graphical Primitives:
    point
    line
        (a line can be one pixel big)
    all other shapes (including curves)


Wed Aug 17 08:02:02 EDT 2016
----------------------------

Random Scan Display Devices
    RSDD's shoot their beam of light directly where they need it
        sort-persistent display
    refreshes only where it needs to be refreshed
        we do not worry about dark pixels
    display buffer:
        this is NOT a frame buffer
        the line definitions are stored in the display buffer
            lines here are stored as start and end coordinates
            four numbers in each row, associated with each line
                (x, y), (x, y)
    display controller/processor:
        takes line definitions from the display buffer and converts them into
            instructions (at the speed of the refresh rate)
        amount of info in the buffer changes from frame to frame
    Pros:
        animation is very natural
            selective erase feature
        can display very complex images
        not heavily dependant on the number of pixels
    Cons:
        RSDD's are expensive
        can not increase the size of the display buffer without altering the
            display controller
        no standard for display buffers
        limited number of colors
            humans can only see a few hundred colors
            it is still important to have more for programmatic analysis

Direct View Storage Tubes
    also a line drawing system
    conceptually CRT based
        long-persistent display
    display buffer:
        similar to RSDD's
    display controller:
        is much cheaper than on RSDD's
        can be very slow
    Pros:
        can have more complex images (doesn't need frequent refreshing)
        inexpensive
        not heavily dependant on number of pixels
        displays can be arbitrarily large
    Cons:
        animation is out of the question
        limited colors
    these displays are often used in technical drawings
        often more expensive only because they are not mass produced


Thu Aug 18 07:59:45 EDT 2016
----------------------------

Raster Scan Display Devices
    pixel resolution is technically the number of pixels total on a raster
        usually is represented as rows * cols
    frame buffer:
        1:1 correspondence to the screen's pixels
    display processor:
        determines the intensity of each pixel

Memory Cells
    pixels are sometimes called memory cells
        1 bit per pixel  = 2 possible grays
        2 bits per pixel = 4 possible grays
        n bits per pixel = 2^n possible grays

Interlacing
    technique for refreshing the screen
        refresh all even number lines, then jump to beginning and refresh odds
        at any pass, displays the image at its half resolution
    reduces required power for display processor
        the human eye CAN detect the difference, though
            usually only when compared side by side

Color
    on most displays, each pixel is made up of three colors
        each pixel is divided into three bands
        each band radiates a "primary color" in terms of RGB
    the frame buffer is also divided this way
    all displays mentioned so far can be considered conceptually CRT based
        here, conceptually, we can think of each pixel as three electron beams

Color Mixtures
    works completely different from paint mixtures
        "additive mixture" vs "subtractive mixtures"
    | Green | Yellow | Red     |
    |-------|--------|---------|
    | Cyan  | White  | Magenta |
    |-------|--------|---------|
            | Blue   |
    we cannot get true black because if the values were truly perfectly
        uncharged, it would take too long to change from black
        for this reason, many systems use a dark gray as black
    grays occur when all values are the same for each color
        in a one bit system, there are two shades of gray
            black and white
            000 and 111
        in a two bit system, there are four shades of gray
            000000, 010101, 101010, 111111


Tue Aug 23 08:02:23 EDT 2016
----------------------------


Color Calculations
    bits/pixel = x
    bits/color = y
    # of color options = 2^x
    # of true grays    = 2^y

Uses for Millions of Pixels
    2^24 color options in most displays
    changes in pixels can be exaggerated to analyze things like:
        heart rate
        sound waves
    medical imaging experts are advocating for more than 2^24 colors

Raster Scan Display Devices
    pros:
        no matter how complex images are, it takes the same amount of time to
            display at the front end
        inexpensive
        filling methods
        free use of color
    cons:
        point based, not line based
            lines are non-decomposable, points are not
            no need to compute which pixels to activate for a line
        scan conversion
            computation of which pixels to make from lines
        lower resolution (must walk over all pixels)
        selective erase is more challenging
            must use scan conversion to selectively erase as well
        lines do not appear straight

Homework:
    search for image magnification talk by Michael Rubinstein


Wed Aug 24 08:04:10 EDT 2016
----------------------------

Color Today
    8 bits per primary color
        2^24 color options
        256 grays

Color Lookup Tables
    originally motivated by memory constraints
        CLT's allow for more colors without increasing the memory size
        fewer bits per pixel = less memory required in the frame buffer
    using a CLT, each pixel in the frame buffer is stored as an index rather
        than a full color
        each color is mapped in the CLT
    ex:
        6 b/pixel in frame buffer
        2^6 entries in the CLT
        64 colors "palette"
            each of these 64 can represent one of 2^n possible colors, where n
                is the number of bits in each row of the CLT
    pros:
        increase in possible colors (arbitrarily many colors)
        overhead is negligible
    cons:
        only 2^n colors can be displayed simultaneously
        lookup overhead

Modern Uses of CLT's
    memory is not an issue in the modern world
    can be used to implement:
        color cycling
        animations
            animation frames can be replaced with the background color until
                they are needed

Example Question:
    256x256 resolution color RGB raster scan display
    frame buffer size is 98304B
    no CLT

    a) how many colors can be displayed simultaneously?
        we have to find the number of bits/pixel
            98304B / ((256*256)pix / 8b)) = 12 bits per pixel
            number of possible colors = 2^12 = 4096
    
    b) using CLT size 13824B, how many colors can be displayed simultaneously?
        answer is still 2^12

    c) using CLT size 13824B, what is the number of color options?
        we need to find the width of the CLT in bits

        Area   = 13824B * 8b
        length = 2^12 = 4096b (from before)
        
        (13824B * 8b)/(4096b) = 27
        2^27 possible colors

    d) how many distinct shades of grey?
        2^(27/3) = 2^9

Dividing Color Possibilities
    in examples so far, the number of possibilities has always been divisible by 3
        if not, sacrifice bits dedicated to blue
        ex:
            14 = 5 shades red 5 shades green 4 shades blue
    this can come up when using multi-resolution systems
        allow the user to change the number of bits per pixel


Thu Aug 25 08:02:17 EDT 2016
----------------------------

!!! Everything from here on is in reference to raster scan devices !!!

Line Drawing Algorithms (Line Scan-Conversion Algorithm)
    most important primitive of any graphics package
        can be used to build other geometric entities
        considered to be the most primitive entity
    most basic task is to decide which pixels need to be activated to create a
        line between two points
        this is called "digitization"

Basic Line-Drawing Algorithm
    y = mx + c
    delta(x) = x1 - x0
    delta(y) = y1 - y0
        delta(var) = difference in the (var) direction
    assumption: delta(x) > delta(y)
        because of this constraint, we only need to activate 1px per column
        therefore, our loop only needs to iterate through the columns once per line
            so, we iterate delta(x) times
            and, we already know what the x values are
    we only need to compute y values, so we solve the equation for y
        y = (delta(y)/delta(x)) * i + y0
            i is the x value we are iterating through
        x = x0 + i
    pseudocode:

        m = delta(y)/delta(x)

        for (i=0; i<= (delta(x) - 1); i++){
            x = x0 + i;
            y = m * i + y0;
            y = trunc(y);
            img[x, y] = white  // line is white, image is frame buffer image
        }
    
    pseudocode walkthrough example:
        x0 = 0
        y0 = 0
        x1 = 8
        y1 = 4
        delta(x) = 8
        delta(y) = 4
        m = 0.5

        i = 0:
            x = 0
            y = 0
        i = 1:
            x = 1
            y = floor(m * i + y0)
            y = floor(.5 * 1 + y0) = floor(.5) = 0

        i = 2:
            x = 2
            y = floor(m * i + y0)
            y = floor(.5 * 2 + y0) = floor(1) = 1
        
    note:
        this only works using delta(x) > delta(y)
            we need special cases for perfectly vertical and horizontal lines
    issues:
        trunc is an expensive operation
        multiplication is more expensive than division
        floats should be avoided as well

Simple Digital Analyzer (DDA)
    very similar to line drawing algorithm
        we still use our assumption of delta(x) > delta(y)
    
    pseudocode:

        yinc = delta(y)/delta(x)
        x = x0
        y = y0
        img[x, y] = w              // w is white

        for ( k = 0; k <= (delta(x)-1); k++){
            x = x+1
            y = y+yinc
            img[x, round(y)] = w   // we can use round or trunc
        }

    walkthrough:
        x0 = 0
        y0 = 0
        yinc = 0.5 // slope
        x = 0
        y = 0

        k = 0:
            x = 0+1 = 1
            y = 0+.5 = .5
            img[x, round(y)] = w   // we can use round or trunc
            img[1, 1] = w

        k = 1:
            x = 1+1 = 2
            y = .5+.5 = 1
            img[x, round(y)] = w   // we can use round or trunc
            img[2, 1] = w


    using round vs trunc:
        round(x) = trunc(x + .5)
        they are equally expensive
        it does not matter much which we use
            everything is approximate anyway
            worst case, the line is off by 1

    pros:
        avoids multiplication (less expensive)
        x = x+1 can be optimized (adding one to a constant is a special
            optimization case)
    issues:
        slowed down by use of floating points

Bresenham's Algorithm
    Dr. Bresenham specialized in mapping floating point algorithms to fixed arithmetic
        this algorithm checks for under/overflow errors, and adjusts accordingly
        only uses ints

    still assuming that delta(x) > delta(y)

    initializations:
        deltay = y1 - y0
        deltax = x1 - x0
        E = 2 * deltay - deltax
        inc1 = 2 * deltay
        inc2 = 2(deltay - deltax)
        y = y0
        x = x0
    
    Loop:
        img[x, y] = w
        
        if E < 0:
            E = E + inc1
        else:
            y = y+1
            E = E + inc2

        x = x + 1

        if x >= x1:
            return
        else:
            continue looping

    pros:
        all ints
        no multiplications/divisions/truncs
        uses compiler-optimized steps
            checking if E < 0 is optimized
            x = x + 1 is optimized
            multiplying by two is also optimized
                handled through bit shifting
        additional work in initialization step is less important because it
            happens per line, not per pixel

    walkthrough:
        deltay = 4
        deltax = 8
        E = 0
        inc1 = 8
        inc2 = -8
        y = 0
        x = 1

        follow flowchart


Tue Aug 30 08:06:27 EDT 2016
----------------------------

Line Attributes (HW requirements)
    dotted lines: 
        skip every other iteration
    dashed lines: 
        gap size = dash size
        can be accomplished using modulo operator
    first argument tells whether to use dotted, dashed, or solid lines

Generalizing the Algorithms (HW requirements)
    one way would be to have separate cases separated by flow control
        this is not how it is done in graphics
        we do not do redundant checks
        instead, we decide whether deltax < deltay or not before the loop
            also check for special cases
            so at least 5 different loops !!! Ask before project about this
        distinct cases:
            positive slope (deltax < deltay)
            negative slope
            perfectly straight
            perfectly horizontal
            perfectly diagonal
                no computation needed for this
                next step is x+1, y+1
    time all of your functions (except dotted/dashed)
        only the critical parts (not the random number generator)

Advantages of Bresenham's Algorithm
    no floating points
        generates lines using only integers
    no expensive arithmetic
        some addition/subtraction
        some multiplication by 2 (bit shift)
            bit shift is faster even than addition
            even shifting by 1 and adding 1 is faster than multiplying by 3
            all of this only works in the integer space, not floating point
    no round or truncate

Line Scan Conversion
    vertical digitization:
        find the intersection of the line with the top and bottom of each
            raster line
        make a square
    horizontal digitization:
        round the other two corners of the square
    finding the intersection points:
        use the endpoints to find the angle of the line with the raster grid
        make a triangle with edge sizes of 1 and w
            1 is the vertical side if we do vertical digitization first
        w = 1/tan(θ) = cot(θ)
        first intersection point is x0 + cot(θ), y0 + 1
        next intersections: x0 + n(cot(θ)), y0 + n
    for each scanline:
        initialX = x0 + (i*cot(θ))
        finalX   = initialX + cot(θ)
        y-value  = y0 + i (only need one, y is one pixel)
        line(solid, Round(x0 + (i * cot(θ)), y-value, Round(finalX), y-value
    this is a very slow solution
        trig functions, round, floating point space all create time issues
    it is still used because there is no dependence between scanlines
        this allows for multiprocessing


Wed Aug 31 07:55:42 EDT 2016
----------------------------

Mid-Term Exam will be on Oct 4th (Tuesday)

Note on Processor Speedup
    if there are two processors for 1000 scanlines, we would use Bresenham's Alg
        Bresenham's algorithm can "kind of" be split up for two processors
        it only needs information from the last line at the place where the
            scanlines cross over

Polyline
    included in most graphics packages
    used to draw polygons where all the lines are connected to each other
        (can be drawn without picking up pen)
    polyline(n, list)
        n    = # of lines
        list = list of y coordinates
            looks like [(0,10), (0,0), (10,0), (10,10), (0,10), (5,15), (10,10)]
    polyline was used for plotters
        there isn't really a technical reason for this function to still exist

Translating 2D to RAM
    2D values do not exist in ram
        everything value one dimensional
    Row major order:
        (x0, y0), (x1, y0) ... (xn, y0), (x1, y0) ...
    to access these values, we need to use an array mapping function
        value in RAM of (x, y) is (base address) + (numrows)(x) + y

Pixel Functions
    putPixel(c, x, y)
        c = color
    img[x, y] = c

    pseudocode:
        address(x, y) = address(0, 0) + y * Width + x
        activate pixel
    this is expensive and happens for every pixel
        each dimension of an array adds another multiplication
    

    if deltaX > deltaY, there are two options:
        address(x + 1, y    ) = address(x, y) + 1
        address(x + 1, y + 1) = address(x, y) + width + 1
    this is the optimized version of putpixel, used in certain algorithms


Thu Sep  1 08:05:06 EDT 2016
----------------------------


Antialiasing
    all algorithms previously discussed have created aliased lines
        "stairstep effect"
    we have also assumed the lines to have 'no thickness'
        geometrically lines do not have thickness
    to antialias the lines we've created, we assume a thickness of 1px
        so the lines are actually a rectangular shape
    to antialias, we find all of the pixels that overlap the new rectangular
        shape and  assign different intensities to them
        intensity is based on the area of the overlap
    as resolutions improve, need for antialiasing decreases

Calculating the Area of a Pixel
    case1: the line intersects the top and bottom of the pixel:
        find the x intercepts of the pixel
            x = x0 + (i + 1)(cot(θ))
            x = x0 + i(cot(θ)
        find the midpoint of those intercepts
            x = x0 + (i + 0.5)cot(θ)
        use the triangle formed by the midpoints to form the polygon formed by
            the intersection into a rectangle
        find the area of the intersection from this information

Circle Generators
    circles do not change no matter how they are rotated
        this includes rotation around an external point
    this makes circles especially useful
        one of the first popular graphics packages was "molecular graphics"
            molecules are made of lines and circles

    simple circle generator:
        assume that the thickness is 1px
        xC = center x value
        yC = center y value
        r  = radius
        if y is iterated through, we just need to solve for x

        (x-xC)² + (y-yC)² = r²
        x = +- (sqrt(r²-(y-yC)²)) + xC
            we need both the positive and negative values to find both halves

        so:
            
        xIn1  =  (sqrt((r-1)²-(y-yC)²)) + xC
        xIn2  = -(sqrt((r-1)²-(y-yC)²)) + xC
        xOut1 =  (sqrt(r²    -(y-yC)²)) + xC
        xOut2 = -(sqrt(r²    -(y-yC)²)) + xC

        xIns  are the inner points of the circle
        xOuts are the outer points


Tue Sep  6 08:01:21 EDT 2016
----------------------------


Issues with Circle Generators
    circles can become rectangles when using few enough pixels
    in the digitized space, the symmetrical properties of circles can be lost
        circle should be mirrored exactly if cut through the center at any angle
        humans are very good at recognizing when a circle isn't perfect
    fixing symmetry
        if a circle is at (xC, yC) and symmetry is broken, we can fix it by moving
            the center to (xC, yC-.5)
        we alternatively could have moved the circle up by .5
    expenses:
        square root is a very expensive algorithm
        have to make sure we are not taking a square root of a negative
        uses floating point math

Another Description of Circle Generation Algorithm
    we create a 1px wide outer/inner circle boundary
        then move the center down .5
    for each scanline:
        find the intersection of both circles with the scanline
        fill in between the intersections, rounding to the nearest integer value
        if there is no intersection with the inner boundary, fill between the
            outer boundaries (??)
    new xOuts:
        xOut1 = -sqrt(r²-(y-yC+.5)²) + xC
        xOut2 =  sqrt(r²-(y-yC+.5)²) + xC
    new xIns:
        xIn1  = -sqrt((r-1)²-(y-yC+.5)²) + xC
        xIn1  =  sqrt((r-1)²-(y-yC+.5)²) + xC

Usefulness of Circle Generators
    circle algorithm can be adjusted to create
        curves
        ovals
        splines
        etc

Bresenham's Circle Generator
    often, when a problem is well defined in the floating point space, you can
        use the integer space by multiplying by a power of ten equal to your
            error tolerance
        multiplying by 10^x before a loop, then dividing back after a loop is common
        this is not possible with this algorithm, but still relevant
    instead of this, Bresenham takes advantage of the circle's symmetry
        we don't need to calculate the entire circle
    from (x, y) on a circle with center (0, 0):
        to cut the complexity in 1/2:
            (x,y), (-x,y)
        1/4:
            (x,y), (-x,y), (x,-y), (-x,-y)
        1/8:
            (x,y), (-x,y), (x,-y), (-x,-y)
            (y,x), (-y,x), (y,-x), (-y,-x)
    we can not go further than this due to line inaccuracy in the digital space
        only straight or perfectly diagonal lines are accurate
    from (x, y) on a circle with center(xC,yC):
        (x+xC,y+yC), (-x+xC,y+yC), (x+xC,-y+yC), (-x+xC,-y+yC)
        (y+xC,x+yC), (-y+xC,x+yC), (y+xC,-x+yC), (-y+xC,-x+yC)

    pseudocode:
        plotCirclePoints():
            setPixel( x+xC,  y+yC,  color)
            setPixel(-x+xC,  y+yC,  color)
            setPixel( x+xC, -y+yC,  color)
            setPixel(-x+xC, -y+yC,  color)
            setPixel( y+xC,  x+yC,  color)
            setPixel(-y+xC,  x+yC,  color)
            setPixel( y+xC, -x+yC,  color)
            setPixel(-y+xC, -x+yC,  color)

        // this function is defined locally to the calling function

        x = 0;
        y = R;
        P = 3 - 2 * R;
        
        if x < y:
            plotCirclePoints()
            if p < 0:
                p = p+(4x)+6
                x = x+1
                return to beginning of loop
            else:
                p = p+4(x-y)+10
                y = y-1
        else:
            if x == y:
                plotCirclePoints()
                return
            else:
                return

    in this pseudocode, p approximates the value of pi
        it over and under adjusts it in a pattern to keep it semi accurate
    this is a very optimized algorithm
        only multiplication by powers of 2, addition, dec/increment, and comparison


Wed Sep  7 07:57:44 EDT 2016
----------------------------

Scan Conversion
    every graphics package has a function called display()
        scan conversion is contained in this function
        every time you are ready to display, you pass line information into the
            scan conversion routine
    this is the end of coverage of scan conversion for 2D images in this class
        from here on, the term "display" includes the scan conversion step

Basic 2D Geometric Transformations (of lines)
    1. Translation
        (x, y)   = the point to be translated
        (x', y') = translated point
        Tx      = displacement in the x direction
        Ty      = displacement in the y direction

        x' = x + Tx
        y' = y + Ty

    2. Scale (around the origin of the coordinate system)
        Sx      = horizontal scaling factor
        Sy      = vertical scaling factor

        x' = x * Sx
        y' = y * Sy

        the origin of this transformation is at (0, 0)

    3. Rotation (around the origin of the coordinate system) (clockwise)
        x' =  x * cos(θ) + y * sin(θ)
        y' = -x * sin(θ) + y * cos(θ)

        we do not worry so much about expensive operations so much for these algorithms
            this is because they are applied to each graphics primitive, not
                each pixel

    in order to apply a transformation to a picture:
        walk over each line, considering the endpoints of the line
        store the new endpoints
        if it is required, call display

Transformation Around a Pivot
    translate shape to origin
    apply scale or rotation
    translate back to original location


Thu Sep  8 08:05:55 EDT 2016
----------------------------


Rotating About a Specified Point
    1. translate by (-xC,- yC)
    2. rotate by theta
    3. translate by (xC, yC)
    this strategy is not optimal, because we have to walk over all the lines 3 times
    we also have to calculate the x' and y' values multiple times
        optimally we would do both of these once

Combining Transformations
    ex: combining translate and rotate

        x' = x + Tx
        y' = y + Ty

        x' =  x * cos(θ) + y * sin(θ)
        y' = -x * sin(θ) + y * cos(θ)

2D Basic Geometric Transformations (Matrix)
    Translation:
                           [ 1  0 0 ]
                 [x y 1] * [ 0  1 0 ] = [x' y' 1]
                           [Tx Ty 1 ]

    Scale:
        
                           [ Sx 0 0 ]
                 [x y 1] * [ 0 Sy 0 ]
                           [ 0  0 1 ]

    Rotate:
                           [cos(θ) -sin(θ) 0]
                 [x y 1] * [sin(θ)  cos(θ) 0]
                           [0       0      1]

    ex:
        translate (10, 20) by (5, 10)

        Tx = 5
        Ty = 10
                    [ 1  0 0 ]
        [10 20 1] * [ 0  1 0 ] = [15 30 1]
                    [ 5 10 1 ]

Rotating About a Specified Point (Matrix)
    ex:
        rotate the triangle (1,1), (2,3), (3,1) by 45 deg about (2,2)
            (translation to origin matrix) * (rotation matrix) * (translation back matrix)
            [ 1  0 0 ]   [.7 -.7 0 ]   [ 1 0 0 ]   [ .7 -.7  0 ]
            [ 0  1 0 ] * [.7  .7 0 ] * [ 0 1 0 ] = [ .7  .7  0 ]
            [-2 -2 1 ]   [ 0   0 1 ]   [ 2 2 1 ]   [-.8   2  1 ]

            multiplication must go right to left

        now we can multiply the final matrix by the points in the original
            picture in the form [x y 1] to get the transformation

Homework: practice matrix multiplication


Tue Sep 13 08:04:21 EDT 2016
----------------------------


For midterm, we can have a one page, one side, handwritten formula sheet
    be able to perform matrix multiplication, translations about a point by hand
    bring calculator

Finding Transformation Matrices
    ex:
        find the transformation matrix which does the following:
            translate the image by (10, 4)
            scale the image by (7,2) about (2,2)
            rotate image by 90 degrees about (3,3)
        
            1. perform translation
            2. translate to zero
            3. scale
            4. translate back
            5. translate to zero
            6. rotate
            7. translate back

        [ 1  0 0 ] [  1  0 0 ] [ 7 0 0 ] [ 1 0 0 ] [  1  0 0 ] [ 0 -1 0 ] [ 1 0 0 ]
        [ 0  1 0 ] [  0  1 0 ] [ 0 2 0 ] [ 0 1 0 ] [  0  1 0 ] [ 1  0 0 ] [ 0 1 0 ]
        [ 10 4 1 ] [ -2 -2 1 ] [ 0 0 1 ] [ 2 2 1 ] [ -3 -3 1 ] [ 0  0 1 ] [ 3 3 1 ]

    ex 2:
        find the transformation matrix which does the following:
            translate the image by (10,4)
            scale the image by (7,2) about (0,0)
            rotate image by 90 degrees about (3,3)
        [ 1  0 0 ] [ 1 0 0 ] [ 7 0 0 ] [ 1 0 0 ] [  1  0 0 ] [ 0 -1 0 ] [ 1 0 0 ]
        [ 0  1 0 ] [ 0 1 0 ] [ 0 2 0 ] [ 0 1 0 ] [  0  1 0 ] [ 1  0 0 ] [ 0 1 0 ]
        [ 10 4 1 ] [ 0 0 1 ] [ 0 0 1 ] [ 0 0 1 ] [ -3 -3 1 ] [ 0  0 1 ] [ 3 3 1 ]

        this makes matrices 2 and 4 identity matrices
            so we can skip these steps
            this is an optimization case

Window to Viewport Transformations
    window into the world is Xw, Yw
    window's coordinates on the screen is Xs, Ys
        we need to compute Xw,Yw in terms of Xs,Ys
    Xs = a * Xw + b
    Ys = c * Yw + d
        a,b,c, and d are constants
    a = (Vx2 - Vx1)/(Wx2 - Wx1)
    b = Vx1 - a * Wx1
    c = (Vy2 - Vy1)/(Wy2 - Wy1)
    d = Vy1 - c * Wy1
        Wy2, Wy1 are the top and bottom limits of the viewport window
        Wx1, Wx2 are the left and right limits of the viewport window
        Vy2, Vy1 are the coordinates of the top/bottom of the viewport window on the screen
        Vx2, Vx1 are the coordinates of the left/right of the viewport window on the screen
    this is a relatively simple linear transformation



Wed Sep 14 08:02:54 EDT 2016
----------------------------


Viewports
    lines are often clipped by the viewing area
        handled by "line clipping algorithm"
        if(left < x < right and bottom < y < top)
            plot point
        else
            adjust to the corresponding value on the edge (based on slope)
    this is expensive and requires redundant computations

Line Clipping Algorithms
    we need to determine which lines are outside of the window of visibility
        some are difficult to test for (partially visible)
            some lines can intersect the viewport but have both endpoints
                outside of the window

Cohen-Sutherland Algorithm
    divides the imaging area into 9 distinct regions:
        extends the viewport by one viewport size in all directions
            _|_|_
            _|_|_
             | |
    assigns a 4-bit code to each region
        bit 1 (xxx1) is set if the region is on the left of the viewing area
        bit 2 (xx1x) is set if the region is on the right of the viewing area
        bit 3 (x1xx) is set if the region is below the viewing area
        bit 4 (1xxx)is set if the region is above the viewing area
             1001 | 1000 | 1010
             ------------------
             0001 | 0000 | 0010
             ------------------
             0101 | 0100 | 0110
    we assign this four bit code to each endpoint that ends in each region
        if we logical or them together and get 4 0's, we know that line is
            completely visible
    algorithm:
        C0 and C1 are the 4-bit codes of a line
        1. if C0 or C1 == 0000:
            line is completely visible
            send coordinates of the line to the scan conversion algorithm
        2. elif C0 and C1 != 0000:
            line is completely outside the viewing area
        (these two checks handle all trivial cases to be skipped)
        3. else:
            the line is potentially visible
            find the intersection of the line with a side of the viewing area
                (extended side if necessary)
            consider the line to be to have two segments
                go through the tests considering each segment if necessary
                    (loop through the if statements again)

    algorithmically, we assume that the boundaries have a "thickness"

    examples:
        completely visible:
            _|_|_
            _|x|_
             | |
            0000 or 0000 = 0000 (if pass)
                draw
        completely invisible:
            x|_|_
            _|_|_
            x| |
            1001 or  1101 = 1101 (if fail)
            1001 and 0101 = 0001 (elif pass)
                skip
        partially visible:
            __|__|__
            __|x_|x_
              |  |
            0000 or  0010 = 0010 (if fail)
            0000 and 0010 = 0000 (elif fail)
                divide into segment A and segment B
                repeat tests
                segment B:
                    __|__|__
                    __|__|xx
                      |  |
                    0010 or  0010 = 0010 (if fail)
                    0010 and 0010 = 0010 (elif pass)
                        skip
                segment A:
                    __|__|__
                    __|xx|__
                      |  |
                    0000 or 0000 = 0000 (if pass)
                        display
        potentially visible (not visible):
        x|x|_
        x|_|_
         | |
        fails if and elif
        divide into two segements (arbitrarily start with horizontal
        intersection)
            segment A:
            _|_|_
            x|_|_
             | |
            0001 and 0001 = 0001 (if fail)
                skip

            segment B:
            x|x|_
            _|_|_
             | |
            1000 and 1001 = (if fail)
            1000 or  1001 = 1000 (elif pass)
                skip (trivial case)

        potentially visible (visible):
        _|x|_
        x|x|_
         | |
         0001 and 1000 = (if fail)
         0001 or 10000 = (elif fail)
         divide into two segments (arbitrarily start with horizontal intersection)
            segment A:
            _|x|_
            _|x|_
             | |
             if fail
             elif fail

                segment A1:
                _|x|_
                _|_|_
                 | |
                 if fail (???)
                 elif pass

                 segment A2:
                _|_|_
                _|x|_
                 | |
                 if pass
                 draw
            segment B:
                _|x|_
                x|x|_
                 | |
                we do not need to test segment B because one of segment A's
                    subsegments passed
                    if a segment passes, it is not necessary to continue process


Thu Sep 15 08:01:33 EDT 2016
----------------------------

Representation of Areas
    1. matrix of intensity values (bitmap representation)
        trivial implementation
    2. using geometry
        uses non-overlapping, closed contour polygons
            when people say n polygons, they usually mean n triangles
            'poligonization' is conversion of an image to triangles
                polygons near boundaries become smaller, larger in the center

Area Filling
    problem can be reduced to polygon filling
        we can fill any area by filling the polygons it is made of
    filling is done scanline by scanline
        for each scanline, find intersections with 2 lines of intersection at a
            time and fill
        (we always want an even number of intersections)


Tue Sep 20 08:02:16 EDT 2016
----------------------------

Area Filling (cont'd)
    bitmap representation is only suitable for very small areas
        characters, smiley faces, etc
        usually a few tens of pixels
    for larger areas, we use polygons
    polygons include all geometric shapes as special cases

Scanline Polygon Filling Algorithm (Y-X Algorithm)
    for each edge of the polygon:
        1. compute all intersections of the edge with the scanlines
            build a list of x, y intersections
        2. sort the list so that intersections for each scanline are grouped
            together, and x values increase
        3. remove the elements from the list in pairs
            [(xa, ya)(xb, yb)] ...
            only plot the pixels between [(xa, ya)(xb, yb)] 
                ya = yb and xa <= xb always during this step

Singularity Problem of the Y-X Algorithm
    if we have a polygon with vertices superimposed exactly on a scanline, we will
        end up with an odd number of intersections 
        we need an even number of intersections for this algorithm to work
    we can "fix" this by considering x to be slightly above the scanline by a tiny amount 

Rule for Implementing Y-X Algorithm
    if y is monotonically increasing or decreasing as you walk up or down,
        count each intersection as one vertex
    if y changes direction as you follow a line, count the intersection where
        the line changes direction as two intersections

    example:
                 /\               
            /\  /  \    /\        
       ___ /__\/____\__/__\____   
        A /  B,B   C \/D   \E     
         /__________________\     



Wed Sep 21 08:03:48 EDT 2016
----------------------------


Boundary Fill Algorithm (flood fill)
    starts from an arbitrary point, fills a polygon recursively
        nearest neighbor algorithm

    floodFill(x, y, fillColor, boundaryColor):
        if (img[x, y] != boundaryColor) and (img[x, y] != fillColor):
            img[x, y] = fillColor
            floodFill(x+-1,  y+-1, fillColor, boundaryColor)
        else
            return

    this algorithm can cause a stack overflow if the area is large enough
        can also be handled scanline-by-scanline

Clipping a Polygon
    for hollow polygons, clip each line with the Cohen-Sutherland algorithm
    for a filled polygon:
        when we say a polygon is "filled", we know the fill color, but have not
            necessarily filled the polygon
        to clip a filled polygon, clip the polygon, then ???
            discussed tomorrow


Thu Sep 22 08:00:51 EDT 2016
----------------------------


Sutherland-Hodgeman Algorithm
    consider a vertex P of the polygon
    walk from P to the next vertex
    if P is inside the VP and the next vertex is also in:
        save the next vertex
    elif P is inside the VP but the next vertex is outside:
        find the intersection of the line with the edge of the VP and save it
    elif P is outside the VP and the next vertex is also outside:
        save nothing
    elif P is outside the VP and the next vertex is inside:
        find the intersection of the line with the edge of the VP
        save the intersection point and the next vertex
        make p the next vertex and continue

Geometric Tables
    vertex table:
        contains a list of vertices
            vertices are unordered and not necessarily part of the same polygon
            vertices are indexed
    edge table:
        contains a list of edges
        contains the indices in the vertex table of connected vertices
    these two tables can precisely define lines in a picture
    geometric transformations can be done to the vertex table without need of
        the edge table
        this prevents redundant transformations at the same vertex point
    polygon table:
        contains a list of adjacent lines (indices from edge table)
        often implemented as "triangle tables"
    surface table:
        list of sets of adjacent polygons (indices from polygon table)
    object table:
        list of surfaces (indices from surface table)

3D Visualization
    parallel projection:
        a cube looks like a square
        often used by engineers
        does not adjust for perspective
            (ignores z values)
        if you want to display on other planes, omit another value
            e.g. xz plane, xy plane, yz plane, etc
        popular for technical drawings
    perspective projection:
        most popular visualization method
        objects closer to the POV are larger
            lengths are equal in model but do not appear to be in display
    intensity queueing:
        objects closer to the POV are brighter
    stereoscopic visualization:
        requires polarized glasses or goggles
        left and right view are from different angles
    kinetic depth:
        relies on motion to imply depth
            uses parallax and opposite motion of rotating sides
    hidden line/surface remover:
        lines and surfaces that should not be visible will not be displayed


Tue Sep 27 08:01:22 EDT 2016
----------------------------


Perspective Projection
    this is the most popular form of 3D visualization
        mimics how the eye views the world
    once we compute and display the projection, it is not stored

Coordinate Systems
    Right-Handed System
        Y is up, X is right, Z is toward the viewer (positive Z is closer)
        the "virtual world" is always a right-handed system
    Left-Handed System
        Y is up, X is right, Z is away from the viewer (positive Z is farther)
        the "eye" or "POV" is often a left-handed system
        "Z" is the viewing direction
    the eye coordinate system and the world coordinate system are separate sets
        of coordinates
    we need a plane to project onto that is between the "eye" and the object

3D Geometric Transformations (Basic)
    in 3D, a line has two points at (x, y, z)
    basic translations around origin:

    1. Translation:
                              [ 1  0  0  0 ]
        [x'y'z'1] = [x y z 1] [ 0  1  0  0 ]
                              [ 0  0  1  0 ]
                              [ Tx Ty Tz 1 ]
    2. Scale:
                              [ Sx 0  0  0 ]
        [x'y'z'1] = [x y z 1] [ 0  Sy 0  0 ]
                              [ 0  0  Sz 0 ]
                              [ 0  0  0  1 ]

    3. Rotation:
        (clockwise) (about Z)
            flip sign of theta for counterclockwise

                              [  cosΘ sinΘ  0    0 ]
        [x'y'z'1] = [x y z 1] [ -sinΘ cosΘ  0    0 ]
                              [  0    0     1    0 ]
                              [  0    0     0    1 ]

        (clockwise) (about Y)

                              [ cosθ  0  -sinθ  0 ]
        [x'y'z'1] = [x y z 1] [ 0     1   0     0 ]
                              [ sinθ  0   cosθ  0 ]
                              [ 0     0   0     1 ]

        (clockwise) (about X)

                              [ 1   0    0    0 ]
        [x'y'z'1] = [x y z 1] [ 0   cos  sin  0 ]
                              [ 0  -sin  cos  0 ]
                              [ 0   0    0    1 ]

Perspective Projection
    "In order to calculate the position on the display screen of the image of a
        point on some object, we must first transform the point from the WCS to
        the ECS, which has its origin fixed at the viewpoint and its Z axis
        pointed in the direction of the view"
            WCS = world coordinate system
            ECS = eye coordinate system
    First step is to define the object in terms of the ECS
        we can do this by using the vewing transformation
            [ Xe Ye Ze 1 ] = [ Xw Yw Zw 1 ] [V]

Very Simple Case of Perspective Projection
    Assumptions:
        the object is defined in the ECS
            as long as we can compute [V] this is not an issue
        the viewpoint is fixed at [0, 0, 0]
            this is always true in the ECS anyway
        the Ze axis intersects the center of the "screen"
            this is the "screen" in the virtual world (plane being projected on)
    the virtual screen is its own 2D coordinate system (Xs, Ys)
        every P(Xe, Ye, Ze) will have a projected point P(Xs, Ys)
        we can form similar triangles from the origin to P and from the origin
            to projected P


Wed Sep 28 08:05:50 EDT 2016
----------------------------


Perspective Projection
    assumptions:
        line of gaze passes through the center of the virtual "screen"
        virtual "screen" is a square
        object of interest is already defined in terms of the ECS
    the eye, line of sight, and point P(Xe, Ye, Ze) form one triangle (Z axis)
    the eye, line of sight, and the point P(Xs, Ys) form another triangle (Z axis) 
        these triangles are similar

                         _.-`|P(Xe, Ye, Ze)
           P'(Xs, Ys)_.-`    |
                _.-`|        |
            _.-`    |S       |
       eye A________|B_______|C

           |----D---|

    S = length(B, P') = half the length of the screen

    Ys/D = Ye/Ze => Ys = (D * Ye)/Ze
    Similarly, considering the XeZe plane:

    Xs/D = Xe/Ze
        so Xs = (D * Xe)/Ze
           Ys = (D * Ye)/Ze

    this has the problem of relying on specific types of units
        (inches, meters, etc)
        so Xs = (D * Xe)/(S * Ze)
           Ys = (D * Ye)/(S * Ze)
    
    these two equations return numbers that may not map to the virtual screen
        well, so we adjust the equation to the virtual screen
        so Xs = ((D * Xe)/(S * Ze)) * Vsx + Vcx
           Ys = ((D * Ye)/(S * Ze)) * Vsy + Vcy
                (Vcx, Vcy) = the center of the virtual screen
                (Vsx, Vsy) = 1/2 * the size of the screen
    these two equations return pixel values on your virtual screen


Thu Sep 29 08:02:20 EDT 2016
----------------------------


Exam Topics:
------------
    Computer Graphics vs Image Processing
    Graphics Applications
    Display Devices
        CRT
        Random Scan Display Devices
        DVST
        Raster Scan
    Grayscale, color, color lookup table
    line scan-conversion algorithm
        simple line drawing algorithm
        DDA (simple)
        Bresenham's algorithm
        parallel line scan-conversion
        line types (solid, dotted, dashed)
    address of a pixel in RAM (optimizing the function that activates a pixel)
    antialiasing
    circle generators (circle scan-conversion)
        simple circle generation (from equation of circle)
        Bresenham's circle generator
            why not divide the circle generation further?
    2D Geometric Transformation
        translate
        scale
        rotate
        concatenation to build more sophisticated transformations
    Window vs Viewport
        window to viewport transformation
    line clipping
        Cohen-Sutherland Algorithm
    representation of area
        bitmap approach
        polygons
        polygon filling algorithm
        filling a closed contour (flood fill and boundary fill)
    clipping a hollow polygon
    clipping a filled polygon
    geometric tables (2D and 3D)
        use to prevent redundant computation
        edge for displaying image, vertex for transformations
    3D visualizations
        parallel projection
        x,y plane from the 3D coordinates
        intensity queueing, stereoscopic views, kinetic, perspective projection

format for homework:
    datalines: 4 integers separated by spaces
        n datalines
    x₀ y₀ x₁ y₁

    ex (triangle):
        10 10 5 5
        5 5 15 5
        15 5 10 10

        (read from a file, say how many lines read)

    clip lines against a viewing area
    test Bresenham first


Wed Oct  5 07:59:43 EDT 2016
----------------------------



                         _.-`|P(Xe, Ye, Ze)
           P'(Xs, Ys)_.-`    |
                _.-`|        |
            _.-`    |S       |
       eye A________|B_______|C

           |----D---|

Monitor Distance
    every monitor is designed to be viewed at a distance D
        if we increase D, the size of objects on the monitor will increase to
            map to the same image size for the distance
        to the eye, there will be no difference

3D Clipping
    we form a pyramid between the eye and the viewing screen
        four lines from the eye to the tangents at each corner of the screen
    everything outside the pyramid is not visible


Thu Oct  6 08:04:27 EDT 2016
----------------------------


3D Clipping
    SEE FIG 1.1
    a point is inside the viewing pyramid if:
        -Ze <= (D/s)Xe <= Ze
        and
        -Ze <= (D/s)Ye <= Ze
    if this is true for both points, a line is visible
        apply the Cohen-Sutherland algorithm to viewport

Clipping Coordinate System
    [ Xc Yc Zc 1 ] = [ Xe Ye Ze 1 ][ N ]
        where:
                [ D/s 0   0   0 ]
            N = [ 0   D/s 0   0 ]
                [ 0   0   1   0 ]
                [ 0   0   0   1 ]
    equivalently:
        Xc = Xe + D/s
        Yc = Ye + D/s
        Ze = Ze

    conditions for clipping using the clipping coordinate system:
        (-Zc <= Xc <= Zc) and (-Zc <= Yc <= Zc)

    -------------- _
    |            | |
    |            | |
    |            | 2Vsy
    |            | |
    |            | _
    -------------- 
    |----2Vsx----|

    Xs = (Xc/Zc) * Vsx + Vcx
    Ys = (Yc/Zc) * Vsy + Vcy

Cohen-Sutherland Algorithm for 3D clipping
    as before, each of the nine regions has a 4-bit code, Cx
        (bit 1 is the least significant bit, i.e. ___x)
        set bit 1 if Xc is to the left of the pyramid
            Xc < -Zc
        set bit 2 if Xc is to the right of the pyramid
            Xc > Zc
        set bit 3 if Xc is to the left of the pyramid
            Yc < -Zc
        set bit 4 if Xc is to the right of the pyramid
            Yc > Zc
    if:    C₀ OR  C₁ == 0000 the line is visible
    elif:  C₀ AND C₁ != 0000 the line is invisible
    else:  line is potentially visible
            compute the intersection of the line with the surface of the
                pyramid (plane)
            make two line segments, test each segment independently
            if one of the segments is visible, you do not need to test the
                other segment


Tue Oct 11 08:09:18 EDT 2016
----------------------------


Recap Summary
    1. convert image from WCS to ECS
        [ Xe Ye Ze 1 ] = [ Xw Yw Zw 1 ] [V]
            V is the viewing transformation
    2. convert to the CCS
        [ Xc Yc Zc 1 ] = [ Xe Ye Ze 1 ] [N]
            a point is visible if: (-Zc <= Xc <= Zc) and (-Zc <= Yc <= Zc)
    3. calculate Xs and Ys
        Xs = (Xc/Zc) * Vsx + Vcx
        Ys = (Yc/Zc) * Vsy + Vcy

The Viewing Transformation
    move the WCS to the center of the ECS
    rotate and flip the WCS until WCS and ECS are superimposed on each other
        we always assume that the Xe axis lies on the Z plane we are working with

    steps to find V:
        1. Translate

    ex:
        consider a cube defined in the WCS by the lines: 
            AB, BC, CD, DA, EF, FG, GH, HE, AE, BF, CG, DH
        the coordinates of these lines are:
              | Xw | Yw | Zw
            ------------
            A | -1 |  1 | -1        A_________B
            B |  1 |  1 | -1        /|       /|
            C |  1 | -1 | -1      E/_|_____F/ |
            D | -1 | -1 | -1       | |      | |
            E | -1 |  1 |  1       | |______|_| 
            F |  1 |  1 |  1       |/D      |/ C
            G |  1 | -1 |  1       |________|
            H | -1 | -1 |  1      H         G

        we will observe this cube from a point (6, 8, 7.5) with the viewing axis
            Ze pointed at the origin of the WCS
        we assume that Xe axis lies on the Z = 7.5 plane
            this is the general case, we always assume that the Xe axis lies on
                the Z plane we are working with

        step 1: Translate
                [ 1   0   0    0 ]
         T₁ =   [ 0   1   0    0 ]
                [ 0   0   1    0 ]
                [-6  -8  -7.5  1 ]
                (-Xe -Ye -Ze)

        step 2: Rotate
                [ 1  0  0  0 ]
          T₂ =  [ 0  0 -1  0 ]
                [ 0  1  0  0 ]
                [ 0  0  0  1 ]

            this rotation matrix is a constant (never will be different)

        step 3: Rotate about Y axis
                [ -.8   0   .6   0 ]
          T₃ =  [   0   1    0   0 ]
                [ -.6   0  -.8   0 ]
                [   0   0    0   1 ]

            this comes from:
                    [ -cosθ    0   sinθ    0 ]
                    [     0    1      0    0 ]
                    [ -sinθ    0  -cosθ    0 ]
                    [     0    0      0    1 ]

            periodic functions here are calculated as:
                sinθ = x/(sqrt(x²+y²))
                cosθ = y/(sqrt(x²+y²))
                    we can do this because it is based on triangles
        
        step 4:
                [ 1   0   0   0 ]
          T₄ =  [ 0  .8  .6   0 ]
                [ 0 -.6  .8   0 ]
                [ 0   0   0   1 ]

            it is a coincidence that these numbers are the same as in step 3

            this matrix come from:
                    [ 1     0     0    0 ]
                    [ 0  cosθ  sinθ    0 ]
                    [ 0 -sinθ  cosθ    0 ]
                    [ 0     0     0    1 ]


            periodic functions here are calculated as:
                sinθ =           z/sqrt(z²+(sqrt(x²+y²)²)
                sinθ = sqrt(x²+y²)/sqrt(z²+(sqrt(x²+y²)²)
        
        step 5: flip the Z axis

                [ 1  0  0  0 ]
           T₅ = [ 0  1  0  0 ]
                [ 0  0 -1  0 ]
                [ 0  0  0  1 ]

            this matrix is constant

        V  = T₁ * T₂ * T ₃ * T₄ * T₅
        VN = T₁ * T₂ * T ₃ * T₄ * T₅ * N


Wed Oct 12 08:04:51 EDT 2016
----------------------------


Viewing Transformation
    [V] translates the WCS to ECS
    
    ex: (same cube from yesterday)
        assume that your VP is 1024 px
        then Vcx = Vcy = Vsy = Vsx = 1023/2
        D = 60
        S = 15

            [ 4 0 0 0 ]
        N = [ 0 4 0 0 ]
            [ 0 0 1 0 ]
            [ 0 0 0 1 ]

             [ -3.2 -1.4 -.5   0 ]
        VN = [  2.4 -1.9 -.6   0 ]
             [    0  3.2 -.6   0 ]
             [    0  0    12.5 1 ]

        [ Xc Yc Zc 1 ] = [ Xw Yw Zw 1 ] * [VN]


        visible if (-Zc <= Xc <= Zc) and (-Zc <= Yc <= Zc):
            all of these are visible

        Xs = (Xc/Zc) * Vsx + Vcx
        Ys = (Yc/Zc) * Vsy + Vcy

          | Xc   | Yc   | Zc   | Xs  | Ys
          -------------------------------
        A |  5.6 | -3.7 | 12.9 | 733 | 366
        B |  -.8 | -6.6 | 12.0 | 477 | 231
        C | -5.6 | -2.7 | 13.3 | 296 | 407
        D |   .8 |   .2 | 14.2 | 540 | 517
        E |  5.6 |  2.7 | 11.7 | 755 | 630
        F |  -.8 |  -.2 | 10.8 | 474 | 504
        G | -5.6 |  3.7 | 12.1 | 274 | 668
        H |   .8 |  6.6 | 13.0 | 543 | 769

Note on 3D clipping
    3D clipping can be accomplished in the following way:
        calculate the table above
        do 2D clipping for Xs, Ys
    this causes redundant computations


Thu Oct 13 08:04:00 EDT 2016
----------------------------

Homework: search for applications of fractals

Fractals
    applications in graphics:
        generating systems like forests, bear fur, etc
    fractal is short for "fractional dimension"
    fractals look the same as we zoom in
        we can not measure fractals with a definite length
    fractals are not considered to be two dimensional
        they have a "fractional dimension"

Simple Fractal
    most sophisticated fractals come from one simple fractal
        this is referred to as the koch curve
    order 0:
       ______________________________
    order 1:
               /\          /\
              /  \        /  \
       ______/    \______/    \______ 
    order 2:
             __/\__      __/\__
             \    /      \    /
       __/\__/    \__/\__/    \__/\__ 

    ...

    to implement:
        take the first line, divide into three equal parts
        make a triangle
        repeat
    this can be done with boxes as well

Computing Dimensions
    for one dimensional entities:

        _____|_____|_____
        similarity relation = 1/3, or r = 1/3 in graphics
        1 = 3 * (1/3)^D
        so D = 1
        we can conclude from this that this entity has one dimension

    for two dimensional entities:
         _____
        |_|_|_|
        |_|_|_|
        |_|_|_|
        r = 1/3
        1 = 9 * (1/3)^D
        so D = 2
        we can conclude from this that this entity has two dimensions

    for three dimensional entities:
           ______
          /_/_/_/|
         /_/_/_/||
        /_/_/_/|/|
        |_|_|_|/|/
        |_|_|_||/
        |_|_|_|/

        imagine this is a 3x3x3 cube
        r = 1/3
        1 = 27*(1/3)^D
        D = 3

    for fractals:
             __/\__      __/\__
             \    /      \    /
       ______/    \______/    \______ 

       r = 1/3
       1 = 4 * (1/3)^D
       D = log(4)/log(3) ~= 1.2857
       we conclude that this is a 1.2857... dimensional entity


Tue Oct 18 08:05:02 EDT 2016
----------------------------


Exam Questions
    1. 
        a) n = 7
           we do not go higher than eight because only there are only eight
                lines that can be perfect in a RSDD (if we divide more than
                this, we will need to use more approximations, which will
                require floating point math)
        b) we move the center of the circle down or up a pixel during
                calculations
        c) Bresenham's algorithm: 
                maps the problem to the integer space
                has no multiplication except by powers of two
    2.
        a) [  1   0 0 ][ 2 0 0 ][ 1  0 0 ]   [  2 0 0 ]
           [  0   1 0 ][ 0 1 0 ][ 0  1 0 ] = [  0 1 0 ]
           [-15 -31 1 ][ 0 0 1 ][15 35 1 ]   [-15 0 1 ]

            (10, 30) -> (5,  30)
            (20, 40) -> (25, 40)
        b) concatenation allows us to apply transformations to a picture
                without walking over the picture many times
        c) true
                this is true for rotations around specific coordinates
    3.
        a) 74, because it takes exactly the same amount of time to access the
                content of a memory cell irrespective of where it is located in
                RAM (it always takes one multiplication and two additions)
        b) use algorithm from notes to describe parallel line scan conversion
                (finding the intersection of lines with each scanline)
        c) give an example of vertex, line, polygon, etc tables and explain
                that we can remove redundant computations using a vertex table
                by applying transformations to only the vertex table
    4.
        a) 512 = 2⁹
           9 bits per px
           270,000B * 8b / 9b = 240,000 pixels
           2³ = 8 grays
        b) 512
                the introduction of the color lookup table does not change the
                    number of simultaneous colors that can be displayed
                CLT
      ---   ------------
       |    |          |
       |    |          |
      512   |  1152B   |
       |    |          |
       |    |          |
      ---   ------------
            |----------|
                 w

                  w  = 1152B * 8b / 512 = 18
                  2⁶ = 64
                  64 grays
    5.
        a) looking for short-persistent phosphor, need for constant refreshing,
                mentioning scan-conversion overhead, lines do not appear
                perfectly straight, lower resolution, more hardware, complexity
                is not dependent on the number of lines in the image
        b) modulo operator in the display loop


Wed Oct 19 07:58:25 EDT 2016
----------------------------


3D Rotation About an Axis Summary
    one way is to line up the object around the axis
        1. translate so that the axis passes through the origin of the coordinate system
        2. rotate about the x axis so that the axis of rotation lies on the XZ plane
        3. rotate about the y axis so that the y axis is lined up with the Z axis
        4. apply the rotation
        5. undo rotation about y axis
        6. undo rotation about x axis
        7. undo translate

    we need to compute the angle of rotation required to get to these positions

Direction-Cosine Method
    
    P₁(x₁, y₁, z₁)
    |    x        -->
    |   / \    V(P₁, P₂)
    |  /    \ 
    |_/______x  P₂(x₂, y₂, z₂)
    Origin

    P₁ and P₂ are vectors

    V defined by [ x₂-x₁, y₂-y₁, z₂-z₁ ]

    the direction cosine of V is:
        a = x/d, b = y/d, c = z/d
            when d = sqrt(x²+y²+z²)

    if vectors have the same directions, the vectors are equal
        this does not mean they lie in the same place
        in order to fix a vector, we need to know one point on the vector

    ex:
        
        P₁(2, 4, 8)
        |    x        -->
        |   / \    V(P₁, P₂)
        |  /    \ 
        |_/______x  P₂(6, 16, 4)
        Origin

        V = [ 4 12 -4 ]
        d = sqrt(16 + 144 + 16) = 13.2

        the direction cosine of V is [ 4/13.2 12/13.2 -4/13.2 ]

3D Rotation About an Arbitrary Axis by a Given Angle
    (x₁, y₁, z₁) lies on the axis of rotation

    1. translate so that the axis passes through the origin of the coordinate system
        we need one point in the vector that lies on the axis of rotation
        T =
                [ 1     0   0  0 ]
                [ 0     1   0  0 ]
                [ 0     0   1  0 ]
                [ -x₁ -y₁ -z₁  1 ]

    2. rotate about the X axis so that the axis of rotation is in the XZ plane
        Rx(α) = 
                [ 1    0    0   0 ]
                [ 0  c/D  b/D   0 ]
                [ 0 -b/D  c/D   0 ]
                [ 0    0    0   1 ]

            cos(α) = c/D, where D = sqrt(b²+c²)

    3. rotate about the Y axis to bring the axis of rotation onto the Z axis
        Ry(β) =
                [  D 0 a 0 ]
                [  0 1 0 0 ]
                [ -a 0 D 0 ]
                [  0 0 0 1 ]
    
            where D = cosβ= sqrt(b²+c²) 
                and sinβ = a

    4. rotate the object by θ degrees about the Z axis
        Rz(θ) = 
                [  cosθ  sinθ  0  0 ]
                [ -sinθ  cosθ  0  0 ]
                [     0  0     1  0 ]
                [     0  0     0  1 ]

            θ is given in the problem definition

    5. undo step 3
        trigonometric identities used here:
            cos(x) =  cos(-x)
            sin(x) = -sin(-x)
        
        Ry(-β) =
                [ D  0 -a  0 ]
                [ 0  1  0  0 ]
                [ a  0  D  0 ]
                [ 0  0  0  1 ]

    6. undo step 2
        Rx(-α) =
                [ 1    0    0   0 ]
                [ 0  c/D -b/D   0 ]
                [ 0  b/D  c/D   0 ]
                [ 0    0    0   1 ]

    7. undo step 1
        T⁻¹ =
                [ 1  0  0  0 ]
                [ 0  1  0  0 ]
                [ 0  0  1  0 ]
                [ x₁ y₁ z₁ 1 ]

    Concatenate:
        R(θ) = T * Rx(α) * Ry(β) * Rz(θ) * Ry(-β) * Rx(-α) * T⁻¹


Thu Oct 20 08:03:27 EDT 2016
----------------------------


Defining the Axis of Rotation
    1. The coordinates of two points on the desired axis
            x₂-x₁, y₂-y₁, z₂-z₁ = x, y, z
            a, b, c = x/D, y/D, z/D where D = sqrt(x²+y²+z²)
    2. We are given the direction cosine (a, b, c) and one point that lies on the axis


Tue Oct 25 08:04:31 EDT 2016
----------------------------


Image Data Structures
    1. Frame buffer representation of an image
        grid of RGB intensity values
    2. Run-length encoding
        if you pick a pixel on either side of a screen, the probability is high
            that they will have the same color
        RL encoding exploits the horizontal coherence between adjacent pixels
        lists the number of adjacent pixels
            this data structure works very naturally with the hardware
        ex:
             _______________ 
            |2|2|2|2|2|4|4|4|  -> 2 5 4 3      -> (2, 5), (4, 3) 
            |1|1|2|2|2|2|1|1|  -> 1 2 2 4 1 2  -> (1, 2), (2, 4), (1, 2)
            | | | | | | | | |  ...

        -> (2, 5), (4, 3), (1, 2), (2, 4), (1, 2)
    3. Quad Tree
        tree where each node has four children
        converts an image to boxes of the same picture
            boxes get smaller until they are 1px in size
        if the all pixels in the image are the same color:
            return color
        else:
            divide int four quadrant
            run recursively on four quadrants
        ex:
             _______________
            |2|2|2|2|4|2|4|4|
            |2|2|2|2|4|4|4|4|
            |2|2|2|2|4|4|4|4|
            |2|2|2|2|4|4|4|4|
            |9|9|9|9|9|9|9|9|
            |1|4|1|8|9|9|9|9|
            |1|4|1|8|9|9|9|9|
            |2|4|1|9|9|9|9|9|
                    ___ 
            order: |1|2|
                   |3|4|

             _______________
            |       |_|_|   |
            |       |_|_|___|
            |       |   |   |
            |_______|___|___|
            |_|_|_|_|       |
            |_|_|_|_|       |
            |_|_|_|_|       |
            |_|_|_|_|_______|

            R,2,R,R,4,2,4,4,4,4,4,
            R,R,9,9,1,4,R,9,9,1,8
            R,1,4,2,4,R,1,8,1,9,9


        Rebuilding the image from the string representation of the quad tree
             _______________
            |       |4|2| 4 |
            |  2    |4|4|___|
            |       | 4 | 4 |
            |_______|___|___|
            |9|9|9|9|       |
            |1|4|1|8|  9    |
            |1|4|1|8|       |
            |2|4|1|9|_______|

        
        Tree Representation:
                 _R__
                / /\ \
               2 /  \ 9
             _R    R_____________
            //\\   /     /  \    \
            R_444  R_   R_   R_   R_
           //\\   //\\ //\\ //\\ //\\
          4244    9914 9918 1424 1819

        
        With R's replaced with averages of children:
                 _5__
                / /\ \
               2 /  \ 9
             _3.9  5.1____________
            //\\   /     /    \   \
           3.5 444 5.8  6.8  2.8  4.8
           //\\   //\\ //\\ //\\ //\\
           4244   9914 9918 1424 1819

        This tree can be used to display the image at different resolutions
            1x1 px:
             ___
            | 5 |
            |   |

            2x2 px:
             _______
            | 2 |3.5|
            |5.1| 9 |

            4x4 px:
             _______________
            |   2   |3.5| 4 |
            |_______|_4_|_4_|
            |5.8|6.8|   9   |
            |2.8|4.8|       |


        this is how resolution scaling is achieved


Wed Oct 26 08:02:09 EDT 2016
----------------------------


Image Data Structures (contd)
    quad trees require an image of 2ⁿ*2ⁿ resolution
        these types of data structures are called 2ⁿ structures
    the ordering of information in a quad tree can be used to rearrange an image
    ex:
         _______
        |1|1|6|6|
        |1|1|6|6|
        |2|1|6|1|
        |3|4|6|2|
    
    R_____
   // \   \
   16 R__  R__
      //\\ //\\
      2134 6162

    3.3
   //\\
   1 6 5.5 3.8
      //\\ //\\
      2134 6162

    1x1 px:
         ___
        |3.3|

    2x2 px:
         ___
        |1|6|
        |3|4|

    4x4 px:
       _______
      | 1 | 6 |
      |___|___|
      |2|1|6|1|
      |3|4|6|2|

    the quad tree data structure is a pyramidal data structure
        we can implement this without using pointers and data structures
        often we will just store the information in a pyramid

                 etc             -------
               256x256         -/_______\-
               512x512       -/___________\-
              1024x1024     /_______________\

    images stored in a pyramidal structure are used heavily in computer vision
        when trying to recognize an object in an image, a robot will start with
            the lower resolutions
        this enables focusing on a section of an image before examining the
            whole image at high resolution
        the summation of all the pixels in all the images of the pyramid above
            a given image is lower than the number of pixels in that image
            this means that we can do computations significantly faster using
                this method
        we can further improve this by looking for objects around the target
            an example is looking for a pen on a desk
                first we can look for the larger object (the desk)
                this limits the range of focus


    Homework:
        google "image pyramid"


Thu Oct 27 08:05:55 EDT 2016
----------------------------

Voxels
    pixels with a third dimension
        have a volume associated with them
    world is considered to be a cube, and your image is embedded in that cube
    we can use the same pyramidal structure by running the same algorithm
        if all colors in the cube are not the same color, decompose into
            smaller cubes and ask the same question for each cube
        _____________             _____________
       /            /|           /     /      /|
      /            / |          /_____/______/ |
     /            /  |         /     /      /| |
    /____________/   |        /_____/______/ | |
    |            |   |        |     |      | |/|
    |            |   |  =>    |     |      | / |
    |            |   /        |_____|______|/| /
    |            |  /         |     |      | |/
    |            | /          |     |      | /
    |____________|/           |_____|______|/

    this is an oct-tree data structure
        each node has 8 children

Mask/Filter/Kernel/..
    same operation
        "mask"   in computer graphics
        "filter" in image processing
        "kernel" in signal processing
    ex:
         _________
        |2|1|0|1|8|
        |1|1|2|6|2|
        |2|3|4|1|1|
        |1|2|4|1|8|

    mask A is 3x3, represented as:
         _____
        |1|1|2|
        |2|1|1|
        |1|1|1|

        1*2+1*1+2*0+2*1+1*1+1*2+1*2+1*3+1*4 = 17
        1*1+1*0+2*1+2*1+1*2+1*6+1*3+1*4+1*1 = 21
        ...
         ______________
        |  |  |  |  |  |
        |  |17|21|..|  |
        |  |..|..|..|  |
        |  |  |  |  |  |

        creates an image two rows and two columns smaller

Expanding a Pyrimadally Stored Image
    Zero-Order Hold Scheme:
                      ___________
                     |2|2|1|1|4|4|
         _____       |2|2|1|1|4|4|
        |2|1|4|      |6|6|1|1|4|4|
        |6|1|4|  =>  |6|6|1|1|4|4|
        |4|4|4|      |4|4|4|4|4|4|
                     |4|4|4|4|4|4|

        creates a boxing effect
            moves up in size in perfect squares

    First-Order Hold Scheme:
                                                       _________ 
         _____        _________        _________      |2|2|1|3|4|
        |2|1|4|      |2| |1| |4|      |2|2|1|3|4|     |4|3|1|3|4|
        |6|1|4|  =>  |6| |1| |4|  =>  |6|4|1|3|4| =>  |6|4|1|3|4|
        |4|4|4|      |4| |4| |4|      |4|4|4|4|4|     |5|4|3|4|4|
                                                      |4|4|4|4|4|

        1. Stretch horizontally
            place a pixel between each pixel horizontally that is the average of
                the two pixels around it
        2. Stretch vertically
            place a pixel between each pixel vertically that is the average of the
                two pixels around it

        this can be used to enhance digital information for computer
            recognition tasks
        creates a 'blurring' effect
            if scaled up enough, eventually creates crosshatching effect
    
    if you subtract the first order expansion from the zero order expansion,
        you end up with black areas where strong boundaries are
        these boundaries end up being the most valuable information for navigation

Algorithms as Masks
    we can implement most of our operations as masks
        GPU's are optimized for masks
    Zero-Order Hold Scheme as a masks:
                       _____________
                      |0|0|0|0|0|0|0|
        _____         |0|2|0|1|0|4|0|            ___
       |2|1|4|        |0|0|0|0|0|0|0|           |1|1|
       |6|1|4|  =>    |0|6|0|1|0|4|0|    MASK   |1|1|
       |4|4|4|        |0|0|0|0|0|0|0|
                      |0|4|0|4|0|4|0|
                      |0|0|0|0|0|0|0|

    First-Order Hold Scheme as a mask:
                       _____________
                      |0|0|0|0|0|0|0|
        _____         |0|3|0|5|0|7|0|           __________
       |3|5|7|        |0|0|0|0|0|0|0|          |.25|.5|.25|
       |2|7|6|  =>    |0|2|0|7|0|6|0|    MASK  | .5| 1| .5|
       |3|4|9|        |0|0|0|0|0|0|0|          |.25|.5|.25|
                      |0|3|0|4|0|9|0|
                      |0|0|0|0|0|0|0|

Tue Nov  1 08:02:00 EDT 2016
----------------------------

Advanced Shading
    attempts to simulate how shading occurs in real life
        surface properties:
            optical properties of surfaces
                (shiny, dull, matte, transparent, refraction, etc)
            position of surfaces
            surface orientation with respect to light source(s)
        light sources:
            light-emitting sources
            light-reflecting sources
            three types of light:
                point light sources:
                    rays come from one point
                distributed light sources:
                    rays are emitted in parallel
                ambient light

Reflections
    the light sources produce light reflections that are scattered in all directions
        this scattered light is called the diffuse reflection
        often results from the surface roughness or graininess
            matte surfaces mainly causes diffuse reflectivity
    shiny objects cause specular reflectivity
        when we see an apple, we can see the whole apple due to diffuse reflectivity, 
            but we see the shiny reflective spot due to  diffuse reflectivity
    point light sources create bright spots called specular reflections

Calculating Diffuse Reflection
    if a surface is exposed only to ambient light, then the intensity of any
        point on a surface can be calculated as follows:
            I = k * Ia
                Ia = intensity of the ambient light
                k = coefficient of reflection
                k is adjusted by the person designing the graphic
                    0 <= K <= 1
        the reflectivity of a mirror would be close to 1
        if the reflectivity is 0, all light is being absorbed
    the intensity of any point on a surface that is exposed only to a point
        light source can be calculated using Lambert's Cosine Law
        at the same distance, a reflection will be brighter the closer the PLS
            is to being perpendicular with the surface


Wed Nov  2 08:01:46 EDT 2016
----------------------------


Exam 2 will be on November 15
Final Exam will be on Dec 13, 8:00am - 11:00am


Steg Images
    typical computer has a byte per color
        this is excessive for human vision
    every keyboard has between 128 and 256 distinct characters/control keys
        for every keypress, a byte is used to represent that key
        the binary representations can be found in the ASCII standard table
    to find information in pixels: (using least significant bits)
       R        G         B         R        G         B
    0000000x|0000000x|00000000x  0000000x|0000000x|0000000x



Thu Nov  3 08:18:22 EDT 2016
----------------------------

Calculating Reflectivity

    Light UNV    
       \   |   /
      d \  |  /
         \ |θ/
    ______\|/______

        UNV = unit normal vector
        I   = (K * Ip(cosθ))/d
            the smaller the angle, the more light will be reflected
            d  = distance from the PLS to the point on the surface
            Ip = the intensity of the PLS
        adding in contribution from ambient light:
            I = (K * Ia) + (K * Ip(cosθ))/d
        if there are multiple light sources:
            I = (K * Ia₁) + (K * Ip₁ * cosθ)/d₁ + (K * Ip₂ * cosθ₂)/d₂ + ...
                this is impossible to do in real time without approximation
        for RGB intensity values:
            Ir = (Kr * Iar) + (Kr * Ip₁r * cosθ₁)/d₁
            Ig = ...
            Ib = ...

    ex:
        Assuming a grey world:

         PLS        PLS
   I=802   \         / I=912
   d=20     \      /   d=24
             \   /
        ___60°\/_45°__
              A
        
        a) find the intensity of diffuse reflection at point A given that the
            intensity of the ambient light is 212 and the coefficient of
            reflection of the surface is 0.4

            I = 0.4 * 212 + (0.4 * 802)/20 * cos30 + (9.4 * 912)/24 * cos45
            I = 109
        
        b) assuming that we have a gray scale system with 8 bits and that the
            maximum intensity of a point on a surface with reflectivity of 0.4
            is 1000 units, find the intensity of the pixel that would represent
            point A

            109/1000 * 100 ~ 11% of the max

            maximum intensity value on a computer = 255
                the intensity of the pixel is 255 * .11 = 28


Tue Nov  8 08:01:48 EST 2016
----------------------------


Exam Two Topics
    Coordinate Systems (in 3D)
        LHS, RHS, WCS, ECS
    3D representations
    Geometric Tables
    Basic 3D Geometric Transformations
        pivot at origin of coordinate system
        one rotation around each fixed axis
    Perspective Projection
        equations for ECS and CCS
        Xs, Ys equations
    3D Clipping
    Fractals
        what does it mean if the fractal dimension is closer to 2 or 1?
        applications of fractals
        remember a fractal of order 0 is a straight line
    Rotation about an arbitrary axis
        how to define a rotation axis
            two points or directionality (direction-cosine)
    Image Data Structures
        frame buffer
        run length encoding
        quad tree
            how to extract NxN picture from quad tree
        pyramids
    Application of Pyramids
    Advanced Shading
    Steganography

    bring a calculator

Pixel Bias
    pixels are biased as a far as their neighbors are concerned
        this is because there is more distance diagonally between pixels than
            vertically or horizontally
                 _______________________
                | sqrt(2) | 1 | sqrt(2) |
                |      1  | x |      1  |
                | sqrt(2) | 1 | sqrt(2) |
        because of this, if we have a one-to-one mapped rotation operation, we
            will stretch an image by sqrt(2) whenever we rotate it


Wed Nov  9 08:02:06 EST 2016
----------------------------


Advanced Shading
    every polygon lies perfectly on a plane
        polygons do not intersect
    we can find the distance between each vertex of a polygon, we can find the
        distance to the point light source
    for each polygon on a surface with a given reflection coefficient, we can
        find the intensity value for the vertices and plug these values into
        our advanced shading model
        using simple interpolation, we can find the shade of all the points
            between the vertices on the polygon boundaries
        we can then use a filling algorithm to fill the polygon with intensity
            values based on the borders

Rotation Using Pixel Values
    it is important to be able to rotate objects at the pixel values
        access only to the "digitized information"
        if you rotate an image pixel by pixel, you will end up with oddities
            caused by rounding errors
            a couple of pixels may map to a single pixel, etc.
            you can also end up with missing pixels this way
                "measles effect"
            trying to solve this problem with a one-to-one mapping algorithm
                will always result in image distortions
    it is possible to accomplish better rotation using a series of smaller
        rotations

Strip-Code Data Structure
    separates shapes into perfectly horizontal lines of the same color
        so each strip has a thickness of one pixel
        they can be defined with four numbers: x1, x2, y, and color
    for each strip:
        x' = x * cosθ + y * sinθ
        y' = y * cosθ - x * sinθ
        this results in updated end coordinates


Thu Nov 10 08:06:10 EST 2016
----------------------------


Strip-Code Rotation
    one issue with strip-code rotation is that after the rotation, you will
        always have more strips than originally
        the closer the rotation angle is to 90, the worse this effect is
    to adjust for this, the algorithm merges adjacent strips of the same color

Architectures for Graphical Computation
    SISD
        Single Instruction on Single Data
        typical processor
    SIMD
        Single Instruction on Multiple Data
        single control, multiple ALUs
        typical GPU
        capable of executing the same instruction in parallel
    MIMD
        multiple controls and ALUs, or networked computers
        multiple SISD's


Wed Nov 16 08:02:57 EST 2016
----------------------------


Image Histograms
    plot intensity values by number of pixels
           |       __
    # of   |  __  /  \__
    pixels | /  \/      \
           |/            \
           ---------------------
           0 1 2 3 ... 2^n-1
           n = # of bits per pixel
    
    the area under the curve is the total number of pixels
    a narrow, dominant peak indicates a low quality image
        low contrast
    multiple peaks may indicate multiple dominant objects in the image
        smaller peaks may also indicate smaller objects
            |  /\      /\
            | /  \    /  \
            |/    \/\/    \/\
            ---------------------
            one or two dominant objects, two small objects
                "one or two" because the background may also provide a peak
    examining a histogram may allow a person to detect sloppy use of steganography


Thu Nov 17 08:05:18 EST 2016
----------------------------


Generating a Histogram
    hist = [ 0, 0, ... ]
    for i = 0 to numRows:
        for j = 0 to numCols:
            hist[img[i, j]] = hist[img[i, j]] + 1

Detecting Low Contrast
    detect a peak and check for the width
        do this by comparing differences between pixel values
        we can detect a peak with more confidence by creating a moving average
            each index in a new average array would represent a cluster of
                values from the hist array averaged together
            cluster groups overlap

Linear Contrast Enhancement
    also called "histogram stretching"
    we "stretch" the peak in the histogram, and zeroize the lower intensity px
            |       /\                  |      / \
            |      /  \            ->   |    /     \
            |_____/    \_____           |__/         \_____
            ---------------------       ---------------------
    
    if img[i,j] <= low
        img[i,j] = 0
    if low < img[i,j] < high
        img[i,j] = ((img[i,j] - low)/(high - low)) * (2^n - 1)
    if img[i,j] >= high
        img[i,j] = 2^n - 1

    this algorithm is optimized for modern cameras using table lookup
        ex: low = 62  high = 65

    Table
    --------------
    0     | 0     |
    1     | 0     |
    2     | 0     |
    3     | 0     |
     ...  | ...   |
    62    | 0     |
    63    | 85    |
    64    | 170   |
    65    | 2^n-1 |
    66    | 2^n-1 |
    67    | 2^n-1 |
    ...   | ...   |
    2^n-1 | 2^n-1 |

    img[i,j] = Table[img[i,j]]
    
    contrast enhancement is only used for visual aesthetic purposes
        this is because the enhanced image contains less information

    Homework: google "image processing contrast enhancement"


Tue Nov 29 08:07:07 EST 2016
----------------------------


Differentiation of Signals
    ex: (intensity values on a scanline)

        2 2 2 2 2 4 6 8 9 10 2 2 2 2

                        __--````````
        __________..--``

        the curve represents some important boundary
        mapping the changes in intensity values:
        0 0 0 0 0 2 2 2 1 1 -8 0 0 0 0

        new line graph:
                  ______
                 |      |__
        _________|         |  ________
                           | |
                           | |
                           | |
                           |_|
        (not to scale)
        
        this transformation is a differentiation operator
            this new graph is the "first derivative"

    in the analog space, the curves will be smoother
    ex:

        First Derivative
                   __..--``````
        _____..--``

        Second Derivative
                _.-``-._
        _____.-`        `-._____

        Third Derivative
                _
              _- -_
        _____-     -_      ______
                     -_  _-
                       ``
    in the third derivative, the place where the line crosses x=0 is a boundary

Noise Reduction
    take each value and average it with its four nearest neighbors
        this cannot be applied to the margins of the picture
    ex:
         _______
        |2|5|6|7|         ___
        |1|2|1|1| ... -> |2|2| ...
        |4|1|2|4|        ...
        ...

    f₂(x, y) = 1/5 SUM(f₁(i, j) for i, j in window size T
            = 1/5(f₁(x, y) + f₁(x-1, y) + f₁(x+1, y) + f₁(x, y-1) + f₁(x, y+1))

    the resulting image suffers from less noise
        this creates a "blurring effect" that is not considered distortion

    applied as a mask:
         ___________
        |  0|1/5|  0|
        |1/5|1/5|1/5|
        |  0|1/5|  0|

    this is not a fair mask because all of the pixels have equal values
        it also does not take corners into account
    a more accurate mask would be:
         _____
        |C|B|C|
        |B|A|B|
        |C|B|C|

        where A + 4B + 4C = 1
            these values are derived from the fact that B is 1 unit from A and
                C is √2 units from A

    the fairness of the mask becomes less important as pixel density increases
        because of this, the previous mask is not longer commonly used

    today, it is more common to use this simple mask for noise reduction:
         ___________
        |1/9|1/9|1/9|
        |1/9|1/9|1/9|
        |1/9|1/9|1/9|

Median Filtering
    takes square groups of (for example) 9 pixels, sorts them, and places the
        median in the center pixel
    this operator is so important that there is a dedicated chip for it on most devices
        even if an image is unrecognizable, it may look good after median filtering
        this can work even if the majority of the pixels in an image are bad
    audio signals in phones also go through smoothing, then median filtering

Homework: google "median filtering"


