Thu Aug 11 08:02:53 EDT 2016
----------------------------

Office Hours
    416 Boyd
    Mon:  3:30PM- 4:30PM
    Tue:  9:30AM-10:30AM
    Wed: 10:00AM-11:00AM
    Thu:  9:30AM-10:30AM
    706-340-4707


Textbook
    Computer Graphics with OpenGL (Hearn, Baker, Carithers)

Graphics vs Image Processsing
    significant overlap
        signal processing is similar
        these three subjects fall under the category of "imaging science"
    typical graphics package:
        input is some sort of description
            describes the image to be drawn
        output is an artificially created image
    typical impage processing package:
        input is a picture
        output is a description (of a picture)
    so, a graphics package and IP package are the inverse of each other

Analog vs Digital Images
    Analog:
        precise and accurate
            absolutely "correct"
        an Analog signal will degrade during transfer/transportation
            ex: using a copier to copy an image over and over again
    Digital:
        approximate
            "kind of correct", not precise
        a digital signal will degrade much more slowly than analog
            uses a corrective mechanism to counter energy loss
                this involves rounding values that are off by small amounts
                thus the signal is exact after transfer
                (correction is implemented at the circuit level)
    conversion from analog to digital signals:
        single signal is continuous while analog
        the signal is divided into small chunks during conversion, rounded
            this is similar to estimation for a curve using taylor expansion
            the final picture is in discrete digits

Discrete vs Continuous Video
    true analog video would have infinite fps
        at one trillion fps, you would be able to see light moving
            trillion fps video exists
            creates storage issues
            also creates copying issues
                copying is the most expensive computer operation

Performance and Video
    high performance computing is pushed by the image processing community
        due to the limitation of the speed of light, a display with billions of
            pixels is not possible on one processor

Applications of Computer Graphics
    any computer's front end is a graphics package
    computer games
    simulators
    molecular graphics
    CAD (computer aided design)

Displaying a Line
    lines do not exist (no thickness)
    computer decides which pixels need to be activated to give the impression
        of a geometric shape
    drawing a line is the most important function of a graphics package

Homework:
    google applications of computer graphics
    google one trillion fps video


Tue Aug 16 08:02:10 EDT 2016
----------------------------

Processor Performance
    there is over a hundred miles of path in an average processor
    smaller processors are faster and use less energy
        this is due to reduced distance
        processor shrinking can be done through photographic technology

Parallel Processing
    adding processors to increas performance can circumvent the issue of
        overheating in denser processors
    each neuron in the brain is a processor
        as humans age, they use neurons
        connectivity between neurons is more responsible for brainpower than
            the number of neurons
        the brain, as an adaptive system, can become more powerful by thinking
        the best possible connectivity would be each neuron being directly
            connected to every other neuron
            evolution does not allow this because each neuron would need n
                connections, where n is the number of total connections
            this would make the brain the size of a house
        we have the same opimization issues with parallel processors

CRT Technology
    electron beam shoots through a series of plates before being projected onto
        the glass screen
        first pair of plates are the focusing plates (very small aperture)
        second pair are horizontal deflection plates
        third pare are vertical deflection plates
    the beam hits a layer of chemical behind the screen
        this causes the point to emit light
    two types of chemical
        short-persistent phosphor
            very short emission
            all animation systems must be short persistent
        long-persistent phosphor
            has to be specifically deactivated
            to erase a full screen of LPP, even with today's technology, takes
                half a second
    all modern laptops are short-persistent
    screen is made up of pixels
        the entire array of pixels is called the raster
        in this example, each pixel can be black white or grey

Graphics Display Options
    Random Scan Display Device
        naturally a line drawing display device
        refres system
            to draw a square, the beam of light moves in a square to activate the
                phosphor in the shape of a square
    RSDD's can be huge without increasing processing power too much

Levels of Grapical Primitives:
    point
    line
        (a line can be one pixel big)
    all other shapes (including curves)


Wed Aug 17 08:02:02 EDT 2016
----------------------------

Random Scan Display Devices
    RSDD's shoot their beam of light directly where they need it
        sort-persistent display
    refreshes only where it needs to be refreshed
        we do not worry about dark pixels
    display buffer:
        this is NOT a frame buffer
        the line definitions are stored in the display buffer
            lines here are stored as start and end coordinates
            four numbers in each row, associated with each line
                (x,y),(x,y)
    display controller/processor:
        takes line definitions from the display buffer and converts them into
            instructions (at the speed of the refresh rate)
        amount of info in the buffer changes from frame to frame
    Pros:
        animation is very natural
            selective erase feature
        can display very complex images
        not heavily dependant on the number of pixels
    Cons:
        RSDD's are expensive
        can not increase the size of the display buffer without altering the
            display controller
        no standard for display buffers
        limited number of colors
            humans can only see a few hundred colors
            it is still important to have more for programmatic analysis

Direct View Storage Tubes
    also a line drawing system
    conceptually CRT based
        long-persistant display
    display buffer:
        similar to RSDD's
    display controller:
        is much cheaper than on RSDD's
        can be very slow
    Pros:
        can have more complex images (doesn't need frequent refreshing)
        inexpensive
        not heavily dependant on number of pixels
        displays can be arbitrarily large
    Cons:
        animation is out of the question
        limited colors
    these displays are often used in technical drawings
        often more expensive only because they are not mass produced


Thu Aug 18 07:59:45 EDT 2016
----------------------------

Raster Scan Display Devices
    pixel resolution is technically the number of pixels total on a raster
        usually is represented as rows x cols
    frame buffer:
        1:1 correspondance to the screen's pixels
    display processor:
        determines the intensity of each pixel

Memory Cells
    pixels are sometimes called memory cells
        1 bit per pixel  = 2 possible grays
        2 bits per pixel = 4 possible grays
        n bits per pixel = 2^n possible grays

Interlacing
    technique for refreshing the screen
        refresh all even number lines, then jump to beginning and refresh odds
        at any pass, displays the image at its half resolution
    reduces required power for display processsor
        the human eye CAN detect the difference, though
            usually only when compared side by side

Color
    on most displays, each pixel is made up of three colors
        each pixel is divided into three bands
        each band radiates a "primary color" in terms of RGB
    the frame buffer is also divided this way
    all displays mentioned so far can be considered conceptually CRT based
        here, conceptually, we can think of each pixel as three electron beams

Color Mixtures
    works completely different from paint mixtures
        "additive mixture" vs "subtractive mixtures"
    | Green | Yellow | Red     |
    ----------------------------
    | Cyan  | White  | Magenta |
    ----------------------------
            | Blue   |
    we cannot get true black because if the values were truly perfectly
        uncharged, it would take too long to change from black
        for this reason, many systems use a dark gray as black
    grays occur when all values are the same for each color
        in a one bit system, there are two shades of gray
            black and white
            000 and 111
        in a two bit system, there are four shades of gray
            000000, 010101, 101010, 111111


Tue Aug 23 08:02:23 EDT 2016
----------------------------


Color Calculations
    bits/pixel = x
    bits/color = y
    # of color options = 2^x
    # of true grays = 2^y

Uses for Millions of Pixels
    2^24 color options in most displays
    changes in pixels can be exaggerated to analyze things like:
        heartrate
        sound waves
    medical imaging experts are advocating for more than 2^24 colors

Raster Scan Display Devices
    pros:
        no matter how complex images are, it takes the same amount of time to
            display at the front end
        inexpensive
        filling methods
        free use of color
    cons:
        point based, not line based
            lines are non-decomposable, points are not
            no need to compute which pixels to activate for a line
        scan conversion
            computation of which pixels to make from lines
        lower resolution (must walk over all pixels)
        selective erase is more challenging
            must use scan conversion to selectively erase as well
        lines do not appear straight

Homework:
    search for image magnification talk by Michael Rubinstein


Wed Aug 24 08:04:10 EDT 2016
----------------------------

Color Today
    8 bits per primary color
        2^24 color options
        256 grays

Color Lookup Tables
    originally motivated by memory constraints
        CLT's allow for more colors without increasing the memory size
        fewer bits per pixel = less memory required in the frame buffer
    using a CLT, each pixel in the frame buffer is stored as an index rather
        than a full color
        each color is mapped in the CLT
    ex:
        6 b/pixel in frame buffer
        2^6 entries in the CLT
        64 colors "pallete"
            each of these 64 can represent one of 2^n possible colors, where n
                is the number of bits in each row of the CLT
    pros:
        increase in possible colors (arbitrarily many colors)
        overhead is negligible
    cons:
        only 2^n colors can be displayed simultaneously
        lookup overhead

Modern Uses of CLT's
    memory is not an issue in the modern world
    can be used to implement:
        color cycling
        animations
            animation frames can be replaced with the background color until
                they are needed

Example Question:
    256x256 resolution color RGB raster scan display
    frame buffer size is 98304B
    no CLT

    a) how many colors can be displayed simultaneously?
        we have to find the number of bits/pixel
            98304B / ((256*256)pix / 8b)) = 12 bits per pixel
            number of possible pixels = 2^12 = 4096
    
    b) using CLT size 13824B, how many colors can be displayed simultaneously?
        answer is still 2^12

    c) using CLT size 13824B, what is the number of color options?
        we need to find the width of the CLT in bits

        Area = 13824B * 8b
        length = 2^12 = 4096b (from before)
        
        (13824B * 8b)/(4096b) = 27
        2^27 possible colors

    d) how many distinct shades of grey?
        2^(27/3) = 2^9

Dividing Color Possibilites
    in examples so far, the number of possibles has always been divisible by 3
        if not, sacrifice bits dedicated to blue
        ex:
            14 = 5 shades red 5 shades green 4 shades blue
    this can come up when using multiresolution systems
        allow the user to change the number of bits per pixel


Thu Aug 25 08:02:17 EDT 2016
----------------------------

!!! Everything from here on is in reference to raster scan devices !!!

Line Drawing Algorithms (Line Scan-Conversion Algorithm)
    most important primitive of any graphics package
        can be used to build other geometric entities
        considered to be the most primitive entity
    most basic task is to decide which pixels need to be activated to create a
        line between two points
        this is called "digitization"

Basic Line-Drawing Algorithm
    y = mx + c
    delta(x) = x1-x0
    dleta(y) = y1-y0
        delta(var) = difference in the (var) direction
    assumption: delta(x) > delta(y)
        because of this constraint, we only need to activate 1px per column
        therefore, our loop only needs to iterate through the columns once per line
            so, we iterate delta(x) times
            and, we already know what the x values are
    we only need to compute y values, so we solve the equation for y
        y = (delta(y)/delta(x)) * i + y0
            i is the x value we are iterating through
        x = x0 + i
    pseudocode:

        m = delta(y)/delta(x)

        for (i=0; i<= (delta(x) - 1); i++){
            x = x0 + i;
            y = m * i + y0;
            y = trunc(y);       // same as floor?
            image[x,y] = white  // line is white, image is frame buffer image
        }
    
    pseudocode walkthrough example:
        x0 = 0
        y0 = 0
        x1 = 8
        y1 = 4
        delta(x) = 8
        delta(y) = 4
        m = 0.5

        i = 0:
            x = 0
            y = 0
        i = 1:
            x = 1
            y = floor(m * i + y0)
            y = floor(.5 * 1 + y0) = floor(.5) = 0

        i = 2:
            x = 2
            y = floor(m * i + y0)
            y = floor(.5 * 2 + y0) = floor(1) = 1
        
    note:
        this only works using dlta(x) > delta(y)
            we need special cases for perfectly vertical and horizontal lines
    issues:
        Trunc is an expensive operation
        multiplication is more expensive than division
        floats should be avoided as well

Simple Digital Analyzer (DDA)
    very similar to line drawing algorithm
        we still use our assumption of delta(x) > delta(y)
    
    pseudocode:

        yinc = delta(y)/delta(x)
        x = x0
        y = y0
        image[x,y] = w              // w is white

        for ( k = 0; k <= (delta(x)-1); k++){
            x = x+1
            y = y+yinc
            image[x,round(y)] = w   // we can use round or trunc
        }

    walkthrough:
        x0 = 0
        y0 = 0
        yinc = 0.5 // slope
        x = 0
        y = 0

        k = 0:
            x = 0+1 = 1
            y = 0+.5 = .5
            image[x,round(y)] = w   // we can use round or trunc
            image[1,1] = w


        k = 1:
            x = 1+1 = 2
            y = .5+.5 = 1
            image[x,round(y)] = w   // we can use round or trunc
            image[2,1] = w


    using round vs trunc:
        round(x) = trunc(x + .5)
        they are equally expensive
        it does not matter much which we use
            everything is approximate anyway
            worst case, the line is off by 1

    pros:
        avoids multiplication (less expensive)
        x = x+1 can be optimized (adding one to a constant is a special
            optimization case)
    issues:
        slowed down by use of floating points

Bresenham's Algorithm
    Dr. Bresenham specialized in mapping floating point algorithms to fixed arithmetic
        this algorithm checks for under/overflow errors, and adjusts accordingly
        only uses ints

    still assuming that delta(x) > delta(y)

    initializations:
        deltay = y1 - y0
        deltax = x1 - x0
        E = 2 * deltay - deltax
        inc1 = 2 * deltay
        inc2 = 2(deltay - deltax)
        y = y0
        x = x0
    
    Loop:
        image[x,y] = w
        
        if E < 0:
            E = E + inc1
        else:
            y = y+1
            E = E + inc2

        x = x + 1

        if x >= x1:
            return
        else:
            continue looping

    pros:
        all ints
        no multiplications/divisions/truncs
        uses compiler-optimized steps
            checking if E < 0 is optimized
            x = x + 1 is optimized
            multiplying by two is also optimized
                handled through bit shifting
        additional work in initialization step is less important because it
            happens per line, not per pixel

    walkthrough:
        deltay = 4
        deltax = 8
        E = 0
        inc1 = 8
        inc2 = -8
        y = 0
        x = 1

        follow flowchart


Tue Aug 30 08:06:27 EDT 2016
----------------------------

Line Attributes (HW requirements)
    dotted lines: 
        skip every other iteration
    dashed lines: 
        gap size = dash size
        can be accomplished using modulo operator
    first argument tells whether to use dotted, dashed, or solid lines

Generalizing the Algorithms (HW requirements)
    one way would be to have separate cases separated by flow control
        this is not how it is done in graphics
        we do not do redundant checks
        instead, we decide whether deltax < deltay or not before the loop
            also check for special cases
            so at least 5 different loops !!! Ask before project about this
        distinct cases:
            positive slope (deltax < deltay)
            negative slope
            perfectly straight
            perfectly horizontal
            perfectly diagonal
                no computation needed for this
                next step is x+1, y+1
    time all of your functions (except dotted/dashed)
        only the critical parts (not the random number generator)

Advantages of Bresenham's Algorithm
    no floating points
        generates lines using only integers
    no expensive arithmetic
        some addition/subtraction
        some multiplication by 2 (bit shift)
            bit shift is faster even than addition
            even shifting by 1 and adding 1 is faster than multiplying by 3
            all of this only works in the integer space, not floating point
    no round or truncate

Line Scan Conversion
    vertical digitization:
        find the intersection of the line with the top and bottom of each
            raster line
        make a square
    horizontal digitization:
        round the other two corners of the square
    finding the intersection points:
        use the endpoints to find the angle of the line with the raster grid
        make a triangle with edge sizes of 1 and w
            1 is the vertical side if we do vertical digitization first
        w = 1/tan(theta) = cot(theta)
        first intersection point is x0 + cot(theta), y0 + 1
        next intersections: x0 + n(cot(theta)), y0+n
    for each scanline:
        initialX = x0 + (i*cot(theta))
        finalX = initialX + cot(theta)
        y-value = y0 + i (only need one, y is one pixel)
        line(solid, Round(x0 + (i * cot(theta)), y-value, Round(finalX), y-value
    this is a very slow solution
        trig functions, round, floating point space all create time issues
    it is still used because there is no dependence between scanlines
        this allows for multiprocessing


Wed Aug 31 07:55:42 EDT 2016
----------------------------

Mid-Term Exam will be on Oct 4th (Tuesday)

Note on Processor Speedup
    if there are two processors for 1000 scanlines, we would use Bresenham's Alg
        Bresenham's algorithm can "kind of" be split up for two processors
        it only needs information from the last line at the place where the
            scanlines cross over

Polyline
    included in most graphics packages
    used to draw polygons where all the lines are connected to each other
        (can be drawn without picking up pen)
    polyline(n, list)
        n = # of lines
        list = list of y coordinates
            looks like [(0,10),(0,0),(10,0),(10,10),(0,10),(5,15),(10,10)]
    polyline was used for plotters
        there isn't really a technical reason for this function to still exist

Translating 2D to RAM
    2D values do not exist in ram
        everything value one dimensional
    Row major order:
        (x0, y0), (x1,y0) ... (xn, y0), (x1, y0) ...
    to access these values, we need to use an array mapping function
        value in RAM of (x,y) is (base address) + (numrows)(x) + y

Pixel Functions
    putPixel(c,x,y)
        c = color
    image[x,y] = c

    pseudocode:
        address(x,y) = address(0,0) + y * Width + x
        activate pixel
    this is expensive and happens for every pixel
        each dimension of an array adds another multiplication
    

    if deltaX > deltaY, there are two options:
        address(x + 1,y) = address(x,y) + 1
        address(x + 1, y + 1) = address(x,y) + width + 1
    this is the optimized version of putpixel, used in certain algorithms


Thu Sep  1 08:05:06 EDT 2016
----------------------------


Antialiasing
    all algorithms previously discussed have created aliased lines
        "stairstep effect"
    we have also assumed the lines to have 'no thickness'
        geometrically lines do not have thickness
    to antialias the lines we've created, we assume a thickness of 1px
        so the lines are actually a rectangular shape
    to antialias, we find all of the pixels that overlap the new rectangular
        shape and  assign different intensities to them
        intensity is based on the area of the overlap
    as resolutions improve, need for antialiasing decreases

Calculating the Area of a Pixel
    case1: the line intersects the top and bottom of the pixel:
        find the x intercepts of the pixel
            x = x0 + (i + 1)(cot(theta))
            x = x0 + i(cot(theta)
        find the midpoint of those intercepts
            x = x0 + (i + 0.5)cot(theta)
        use the triangle formed by the midpoints to form the polyon formed by the
            intersection into a rectangle
        find the area of the intersection from this information

Circle Generators
    circles do not change no matter how they are rotated
        this includes rotation around an external point
    this makes circles especially useful
        one of the first popular graphics packages was "molecular graphics"
            molecules are made of lines and circles

    simple circle generator:
        assume that the thickness is 1px
        xC = center x value
        yC = center y value
        r = radius
        if y is iterated through, we just need to slove for x

        (x-xC)² + (y-yC)² = r²
        x = +- (sqrt(r²-(y-yC)²)) + xC
            we need both the positive and negative values to find both halves

        so:
            
        xIn1 = + (sqrt((r-1)²-(y-yC)²)) + xC
        xIn2 = - (sqrt((r-1)²-(y-yC)²)) + xC
        xOut1= +- (sqrt(r²-(y-yC)²)) + xC
        xOut2 = - (sqrt(r²-(y-yC)²)) + xC

        xIns are the inner points of the circle
        xOuts are the outer points


Tue Sep  6 08:01:21 EDT 2016
----------------------------


Issues with Circle Generators
    circles can become rectangles when using few enough pixels
    in the digitized space, the symmetrical properties of circles can be lost
        circle should be mirrored exactly if cut through the center at any angle
        humans are very good at recognizing when a circle isn't perfect
    fixing symmetry
        if a circle is at (xC, yC) and symmetry is broken, we can fix it by moving
            the center to (xC,yC-.5)
        we alternatively could have moved the circle up by .5
    expenses:
        square root is a very expensive algorithm
        have to make sure we are not taking a square root of a negative
        uses floating point math

Another Description of Circle Generation Algorithm
    we create a 1px wide outer/inner circle boundary
        then move the center down .5
    for each scanline:
        find the intersection of both circles with the scanline
        fill in between the intersections, rounding to the nearest integer value
        if there is no intersection with the inner boundary, fill between the
            outer boundaries (??)
    new xOuts
        xOut1 = -sqrt(r²-(y-yC+.5)²) + xC
        xOut2 =  sqrt(r²-(y-yC+.5)²) + xC
    new xIns
        xIn1  = -sqrt((r-1)²-(y-yC+.5)²) + xC
        xIn1  =  sqrt((r-1)²-(y-yC+.5)²) + xC

Usefulness of Circle Generators
    circle algorithm can be adjusted to create
        curves
        ovals
        splines
        etc

Bresenham's Circle Generator
    often, when a problem is well defined in the floating point space, you can
        use the integer space by multiply by a power of ten equal to your error tolerance
        multiplying by 10^x before a loop, then dividing back after a loop is common
        this is not possible with this algorithm, but still relevant
    instead of this, Bresenham takes advantage of the circle's symmetry
        we don't need to calculate the entire circle
    from (x,y) on a circle with center (0,0):
        to cut the complexity in 1/2:
            (x,y),(-x,y)
        1/4:
            (x,y),(-x,y),(x,-y),(-x,-y)
        1/8:
            (x,y),(-x,y),(x,-y),(-x,-y)
            (y,x),(-y,x),(y,-x),(-y,-x)
    we can not go further than this due to line inaccuracy in the digital space
        only straight or perfectly diagonal lines are accurate
    from (x,y) on a circle with center(xC,yC):
        (x+xC,y+yC),(-x+xC,y+yC),(x+xC,-y+yC),(-x+xC,-y+yC)
        (y+xC,x+yC),(-y+xC,x+yC),(y+xC,-x+yC),(-y+xC,-x+yC)

    pseudocode:
        plotCirclePoints():
            setPixel( x+xC, y+yC, color)
            setPixel(-x+xC, y+yC, color)
            setPixel( x+xC,-y+yC, color)
            setPixel(-x+xC,-y+yC, color)
            setPixel( y+xC, x+yC, color)
            setPixel(-y+xC, x+yC, color)
            setPixel( y+xC,-x+yC, color)
            setPixel(-y+xC,-x+yC, color)

        // this function is defined locally to the calling function

        x = 0;
        y = R;
        P = 3 - 2 * R;
        
        if x < y:
            plotCirclePoints()
            if p < 0:
                p=p+(4x)+6
                x=x+1
                return to beginning of loop
            else:
                p=p+4(x-y)+10
                y=y-1
        else:
            if x == y:
                plotCirclePoints()
                return
            else:
                return

    in this pseudocode, p approximates the value of pi
        it over and under adjusts it in a pattern to keep it semi accurate
    this is a very optimized algorithm
        only multiplication by powers of 2, addition, dec/increment, and comparison


Wed Sep  7 07:57:44 EDT 2016
----------------------------

Scan Conversion
    every graphics package has a function called display()
        scan conversion is contained in this function
        every time you are ready to display, you pass line information into the
            scan conversion routine
    this is the end of coverage of scan conversion for 2D images in this class
        from here on, the term "display" includes the scan conversion step

Basic 2D Geometric Transformations (of lines)
    1. Translation
        (x,y)   = the point to be translated
        (x',y') = translated point
        Tx      = displacement in the x direction
        Ty      = displacement in the y direction

        x' = x + Tx
        y' = y + Ty

    2. Scale (around the origin of the coordinate system)
        Sx      = horizontal scaling factor
        Sy      = vertical scaling factor

        x' = x * Sx
        y' = y * Sy

        the origin of this transformation is at (0,0)

    3. Rotation (around the origin of the coordinate system) (clockwise)
        x' =  x * cos(theta) + y * sin(theta)
        y' = -x * sin(theta) + y * cos(theta)

        we do not worry so much about expensive operations so much for these algorithms
            this is because they are applied to each graphics primitive, not
                each pixel

    in order to apply a transformation to a picture:
        walk over each line, considering the endpoints of the line
        store the new endpoints
        if it is required, call display

Transformation Around a Pivot
    translate shape to origin
    apply scale or rotation
    translate back to original location


Thu Sep  8 08:05:55 EDT 2016
----------------------------


Rotating About a Specified Point
    1. translate by (-xC,-yC)
    2. rotate by theta
    3. translate by (xC, yC)
    this strategy is not optimal, because we have to walk over all the lines 3 times
    we also have to calculate the x' and y' values multiple times
        optimally we would do both of these once

Combining Transformations
    ex: combining translate and rotate

        x' = x + Tx
        y' = y + Ty

        x' =  x * cos(theta) + y * sin(theta)
        y' = -x * sin(theta) + y * cos(theta)

2D Basic Gemortric Transformations (Matrix)
    Translation:
                           [ 1  0 0 ]
                 [x y 1] * [ 0  1 0 ] = [x' y' 1]
                           [Tx Ty 1 ]

    Scale:
        
                           [ Sx 0 0 ]
                 [x y 1] * [ 0 Sy 0 ]
                           [ 0  0 1 ]

    Rotate:
                           [cos(theta) -sin(theta) 0]
                 [x y 1] * [sin(theta)  cos(theta) 0]
                           [0           0          1]

    ex:
        translate (10, 20) by (5, 10)

        Tx = 5
        Ty = 10
                    [ 1  0 0 ]
        [10 20 1] * [ 0  1 0 ] = [15 30 1]
                    [ 5 10 1 ]

Rotating About a Specified Point (Matrix)
    ex:
        rotate the triangle (1,1),(2,3),(3,1) by 45 deg about (2,2)
            (translation to origin matrix) * (rotation matrix) * (translation back matrix)
            [ 1  0 0 ]   [.7 -.7 0 ]   [ 1 0 0 ]   [ .7 -.7  0 ]
            [ 0  1 0 ] * [.7  .7 0 ] * [ 0 1 0 ] = [ .7  .7  0 ]
            [-2 -2 1 ]   [ 0   0 1 ]   [ 2 2 1 ]   [-.8   2  1 ]

            multiplication must go right to left

        now we can multiply the final matrix by the points in the original
            picture in the form [x y 1] to get the transformaiton

Homework: practice matrix multiplication


Tue Sep 13 08:04:21 EDT 2016
----------------------------


For midterm, we can have a one page, one side, handwritten formula sheet
    be able to perform matrix multiplication, translations about a point by hand
    bring calculator

Finding Transformation Matrices
    ex:
        find the transformation matrix which does the following:
            translate the image by (10,4)
            scale the image by (7,2) about (2,2)
            rotate image by 90 degrees about (3,3)
        
            1. perform translation
            2. translate to zero
            3. scale
            4. translate back
            5. translate to zero
            6. rotate
            7. translate back

        [ 1  0 0 ] [  1  0 0 ] [ 7 0 0 ] [ 1 0 0 ] [  1  0 0 ] [ 0 -1 0 ] [ 1 0 0 ]
        [ 0  1 0 ] [  0  1 0 ] [ 0 2 0 ] [ 0 1 0 ] [  0  1 0 ] [ 1  0 0 ] [ 0 1 0 ]
        [ 10 4 1 ] [ -2 -2 1 ] [ 0 0 1 ] [ 2 2 1 ] [ -3 -3 1 ] [ 0  0 1 ] [ 3 3 1 ]

    ex 2:
        find the transformation matrix which does the following:
            translate the image by (10,4)
            scale the image by (7,2) about (0,0)
            rotate image by 90 degrees about (3,3)
        [ 1  0 0 ] [ 1 0 0 ] [ 7 0 0 ] [ 1 0 0 ] [  1  0 0 ] [ 0 -1 0 ] [ 1 0 0 ]
        [ 0  1 0 ] [ 0 1 0 ] [ 0 2 0 ] [ 0 1 0 ] [  0  1 0 ] [ 1  0 0 ] [ 0 1 0 ]
        [ 10 4 1 ] [ 0 0 1 ] [ 0 0 1 ] [ 0 0 1 ] [ -3 -3 1 ] [ 0  0 1 ] [ 3 3 1 ]

        this makes matrices 2 and 4 identity matrices
            so we can skip these steps
            this is an optimization case

Window to Viewport Transformations
    window into the world is Xw, Yw
    window's coordinates on the screen is Xs, Ys
        we need to compute Xw,Yw in terms of Xs,Ys
    Xs = a * Xw + b
    Ys = c * Yw + d
        a,b,c, and d are constants
    a = (Vx2 - Vx1)/(Wx2 - Wx1)
    b = Vx1 - a * Wx1
    c = (Vy2 - Vy1)/(Wy2 - Wy1)
    d = Vy1 - c * Wy1
        Wy2, Wy1 are the top and bottom limits of the viewport window
        Wx1, Wx2 are the left and right limits of the viewport window
        Vy2, Vy1 are the coordinates of the top/bottom of the viewport window on the screen
        Vx2, Vx1 are the coordinates of the left/right of the viewport window on the screen
    this is a relatively simple linear transformation



Wed Sep 14 08:02:54 EDT 2016
----------------------------


Viewports
    lines are often clipped by the viewing area
        handled by "line clipping algorithm"
        if(left < x < right and bottom < y < top)
            plot point
        else
            adjust to the corresponding value on the edge (based on slope)
    this is expensive and requires redundant computations

Line Clipping Algorithms
    we need to determine which lines are outside of the window of visibility
        some are difficult to test for (partially visible)
            some lines can intersect the viewport but have both endpoints
                outside of the window

Cohen-Sutherland Algorithm
    divides the imaging area into 9 distict regions:
        extends the viewport by one viewport size in all directions
            _|_|_
            _|_|_
             | |
    assigns a 4-bit code to each region
        bit 1 (xxx1) is set if the region is on the left of the viewing area
        bit 2 (xx1x) is set if the region is on the right of the viewing area
        bit 3 (x1xx) is set if the region is below the viewing area
        bit 4 (1xxx)is set if the region is above the viewing area
             1001 | 1000 | 1010
             ------------------
             0001 | 0000 | 0010
             ------------------
             0101 | 0100 | 0110
    we assign this four bit code to each endpoint that ends in each region
        if we logical or them together and get 4 0's, we know that line is
            completely visible
    algorithm:
        C0 and C1 are the 4-bit codes of a line
        1. if C0 or C1 == 0000:
            line is completely visible
            send coordinates of the line to the scan conversion algorithm
        2. elif C0 and C1 != 0000:
            line is completely outside the viewing area
        (these two checks handle all trivial cases to be skipped)
        3. else:
            the line is potentially visible
            find the intersection of the line with a side of the viewing area
                (extended side if necessary
            consider the line to be to have two segments
                go through the tests considering each segment if necessary
                    (loop through the if statements again)

    algorithmically, we assume that the boundaries have a "thickness"

    examples:
        completely visible:
            _|_|_
            _|x|_
             | |
            0000 or 0000 = 0000 (if pass)
            draw
        completely invisible:
            x|_|_
            _|_|_
            x| |
            1001 or 1101 = 1101 (if fail)
            1001 and 0101 = 0001 (elif pass)
            skip
        partially visible:
            __|__|__
            __|x_|x_
              |  |
            0000 or 0010 = 0010 (if fail)
            0000 and 0010 = 0000 (elif fail)
            divide into segment A and segment B
            repeat tests
                segment B:
                    __|__|__
                    __|__|xx
                     | |
                    0010 or 0010 = 0010 (if fail)
                    0010 and 0010 = 0010 (elif pass)
                    skip
                segment A:
                    __|__|__
                    __|xx|__
                      |  |
                    0000 or 0000 = 0000 (if pass)
                    display
        potentially visible (not visible):
        x|x|_
        x|_|_
         | |
        fails if and elif
        divide into two segements (arbitrarily start with horizontal
        intersection)
            segment A:
            _|_|_
            x|_|_
             | |
            0001 and 0001 = 0001 (if fail)
            skip

            segment B:
            x|x|_
            _|_|_
             | |
            1000 and 1001 = (if fail)
            1000 or 1001 = 1000 (elif pass)
            skip (trivial case)

        potentially visible (visible):
        _|x|_
        x|x|_
         | |
         0001 and 1000 = (if fail)
         0001 or 10000 = (elif fail)
         divide into two segments (arbitrarily start with horizontal intersection)
            segment A:
            _|x|_
            _|x|_
             | |
             if fail
             elif fail

                segment A1:
                _|x|_
                _|_|_
                 | |
                 if fail (???)
                 elif pass

                 segment A2:
                _|_|_
                _|x|_
                 | |
                 if pass
                 draw
            segment B:
                _|x|_
                x|x|_
                 | |
                we do not need to test segment B because one of segment A's
                    subsegments passed
                    if a segment passes, it is not necessary to continue process


Thu Sep 15 08:01:33 EDT 2016
----------------------------

Representation of Areas
    1. matrix of intensity values (bitmap representation)
        trivial implementation
    2. using geometry
        uses non-overlapping, closed contour polygons
            when people say n polygons, they usually mean n triangles
            'poligonization' is conversion of an image to triangles
                polygons near boundaries become smaller, larger in the center

Area Filling
    problem can be reduced to polygon filling
        we can fill any area by filling the polygons it is made of
    filling is done scanline by scanline
        for each scanline, find intersections with 2 lines of intersection at a
            time and fill
        (we always want an even number of intersections)


Tue Sep 20 08:02:16 EDT 2016
----------------------------

Area Filling (cont'd)
    bitmap representation is only suitable for very small areas
        characters, smiley faces, etc
        usually a few tens of pixels
    for larger areas, we use polygons
    polygons include all geometric shapes as special cases

Scanline Polygon Filling Algoritm (Y-X Algorithm)
    for each edge of the polygon:
        1. compute all intersections of the edge with the scanlines
            build a list of x,y intersections
        2. sort the list so that intersections for each scanline are grouped
            together, and x values increase
        3. remove the elements from the list in pairs
            [(xa, ya)(xb,yb)] ...
            only plot the pixels between [(xa, ya)(xb,yb)] 
                ya = yb and xa <= xb always during this step

Singularity Problem of the Y-X Algorithm
    if we have a polygon with vertices superimposed exactly on a scanline, we will
        end up with an odd number of intersections 
        we need an even number of intersections for this algorithm to work
    we can "fix" this by considering x to be slightly above the scanline by a tiny amount 

Rule for Implementing Y-X Algorithm
    if y is monotonically increasing or decreaseing as you walk up or down,
        count each intersection as one vertex
    if y changes direction as you follow a line, count the intersection where
        the line changes direction as two intersections

    example:
                 /\               
            /\  /  \    /\        
       ___ /__\/____\__/__\____   
        A /  B,B   C \/D   \E     
         /__________________\     



Wed Sep 21 08:03:48 EDT 2016
----------------------------


Boundary Fill Algorithm (flood fill)
    starts from an arbitrary point, fills a polygon recursively
        nearest neighbor algorithm

    floodFill(x,y,fillColor,boundaryColor):
        if (image[x,y] != boundaryColor) and (image[x,y] != fillColor):
            image[x,y] = fillColor
            floodFill(x+-1,y+-1,fillColor,boundaryColor)
        else
            return

    this algorithm can cause a stack overflow if the area is large enough
        can also be handled scanline-by-scanline

Clipping a Polygon
    for hollow polygons, clip each line with the Cohen-Sutherland algorithm
    for a filled polygon:
        when we say a polygon is "filled", we know the fill color, but have not
            necessarily filled the polygon
        to clip a filled polygon, clip the polygon, then ???
            discussed tomorrow


Thu Sep 22 08:00:51 EDT 2016
----------------------------


Sutherland-Hodgeman Algorithm
    consider a vertex P of the polygon
    walk from P to the next vertex
    if P is inside the VP and the next vertex is also in:
        save the next vertex
    elif P is inside the VP but the next vertex is outside:
        find the intersection of the line with the edge of the VP and save it
    elif P is outside the VP and the next vertex is also outside:
        save nothing
    elif P is outside the VP and the next vertex is inside:
        find the intersection of the line with the edge of the VP
        save the intersection point and the next vertex
        make p the next vertex and continue

Geometric Tables
    vertex table:
        contains a list of vertices
            verticies are unordered and not necessarily part of the same polygon
            vertices are indexed
    edge table:
        contains a list of edges
        contains the indices in the vertex table of connected vertices
    these two tables can precisely define lines in a picture
    geometric transformations can be done to the vertex table without need of
        the edge table
        this prevents redundant transformations at the same vertex point
    polygon table:
        contains a list of adjacent lines (indices from edge table)
        often implemented as "triangle tables"
    surface table:
        list of sets of adjacent polygons (indices from polygon table)
    object table:
        list of surfaces (indices from surface table)

3D Visualization
    parallel projection:
        a cube looks like a sphere
        often used by engineers
        does not adjust for perspective
            (ignores z values)
        if you want to display on other planes, omit another value
            e.g. xz plane, xy plane, yz plane, etc
        popular for technical drawings
    perspective projection:
        most popular visualization method
        objects closer to the POV are larger
            lengths are equal in model but do not appear to be in display
    intensity queueing:
        objects closer to the POV are brighter
    stereoscopic visualizatoin:
        requires polarized glasses or goggles
        left and right view are from different angles
    kenetic depth:
        relies on motion to imply depth
            uses parallax and opposite motion of rotating sides
    hidden line/surface remover:
        lines and surfaces that should not be visible will not be displayed


Tue Sep 27 08:01:22 EDT 2016
----------------------------


Perspective Projection
    this is the most popular form of 3D visualization
        mimics how the eye views the world
    once we compute and display the projection, it is not stored

Coordinate Systems
    Right-Handed System
        Y is up, X is right, Z is toward the viewer (positive Z is closer)
        the "virtual world" is always a right-handed system
    Left-Handed System
        Y is up, X is right, Z is away from the viewer (positive Z is farther)
        the "eye" or "POV" is often a left-handed system
        "Z" is the viewing direction
    the eye coordinate system and the world coordinate system are separate sets
        of coordinates
    we need a plane to project onto that is between the "eye" and the object

3D Geometric Transformations (Basic)
    in 3D, a line has two points at (x,y,z)
    basic translations around origin:

    1. Translation:
                              [ 1  0  0  0 ]
        [x'y'z'1] = [x y z 1] [ 0  1  0  0 ]
                              [ 0  0  1  0 ]
                              [ Tx Ty Tz 1 ]
    2. Scale:
                              [ Sx 0  0  0 ]
        [x'y'z'1] = [x y z 1] [ 0  Sy 0  0 ]
                              [ 0  0  Sz 0 ]
                              [ 0  0  0  1 ]

    3. Rotation:
        (clockwise) (about Z)
            flip sign of theta for counterclockwise

                              [  cosΘ sinΘ  0    0 ]
        [x'y'z'1] = [x y z 1] [ -sinΘ cosΘ  0    0 ]
                              [  0    0     1    0 ]
                              [  0    0     0    1 ]

        (clockwise) (about Y)

                              [ cosθ  0  -sinθ  0 ]
        [x'y'z'1] = [x y z 1] [ 0     1   0     0 ]
                              [ sinθ  0   cosθ  0 ]
                              [ 0     0   0     1 ]

        (clockwise) (about X)

                              [ 1   0    0    0 ]
        [x'y'z'1] = [x y z 1] [ 0   cos  sin  0 ]
                              [ 0  -sin  cos  0 ]
                              [ 0   0    0    1 ]

Perspective Projection
    "In order to calculate the position on the display screen of the image of a
        point on some object, we must first transform the point from the WCS to
        the ECS, which has its origin fixed at the viewpoint and its Z axis
        pointed in the direction of the view"
            WCS = world coordinate system
            ECS = eye coordinate system
    First step is to define the object in terms of the ECS
        we can do this by using the vewing transformation
            [ Xe Ye Ze 1 ] = [ Xw Yw Zw 1 ] [V]

Very Simple Case of Perspective Projection
    Assumptions:
        the object is defined in the ECS
            as long as we can compute [V] this is not an issue
        the viewpoint is fixed at [0,0,0]
            this is always true in the ECS anyway
        the Ze axis intersects the center of the "screen"
            this is the "screen" in the virtual world (plane being projected on)
    the virtual screen is its own 2D coordinate system (Xs, Ys)
        every P(Xe,Ye,Ze) will have a projected point P(Xs,Ys)
        we can form similar triangles from the orgin to P and from the origin
            to projeceted P


Wed Sep 28 08:05:50 EDT 2016
----------------------------


Perspective Projection
    assumptions:
        line of gaze passes through the center of the virtual "screen"
        virtual "screen" is a square
        object of interest is already defined in terms of the ECS
    the eye, line of sight, and point P(Xe,Ye,Ze) form one triangle (Z axis)
    the eye, line of site, and the point P(Xs,Ys) form another triangle (Z axis) 
        these triangles are similar

                         _.-`|P(Xe,Ye,Ze)
           P'(Xs,Ys) _.-`    |
                _.-`|        |
            _.-`    |S       |
       eye A________|B_______|C

           |----D---|

    S = length(B, P') = half the length of the screen

    Ys/D = Ye/Ze => Ys= (D * Ye)/Ze
    Similarly, considering the XeZe plane:

    Xs/D = Xe/Ze
        so Xs = (D * Xe)/Ze
           Ys = (D * Ye)/Ze

    this has the problem of relying on specific types of units
        (inches, meters, etc)
        so Xs = (D * Xe)/(S * Ze)
           Ys = (D * Ye)/(S * Ze)
    
    these two equations return numbers that may not map to the virtual screen
        well, so we adjust the equation to the virtual screen
        so Xs = ((D * Xe)/(S * Ze)) * Vsx + Vcx
           Ys = ((D * Ye)/(S * Ze)) * Vsy + Vcy
                (Vcx,Vcy) = the center of the virtual screen
                Vsx, Vsy = 1/2 * the size of the screen
    these two equations return pixel values on your virtual screen


Thu Sep 29 08:02:20 EDT 2016
----------------------------


Exam Topics:
------------
    Computer Graphics vs Image Processing
    Graphics Applications
    Display Devices
        CRT
        Random Scan Display Devices
        DVST
        Raster Scan
    Grayscale, color, color, color lookup table
    line scan-conversion algorithm
        simple line drawing algorithm
        DDA (simple)
        Bresenham's algorithm
        parallel line scan-conversion
        line types (solid, dotted, dashed)
    address of a pixel in RAM (optimizing the function that activates a pixel)
    antialiasing
    circle generators (circle scan-conversion)
        simple circle generation (from equation of circle)
        bresenham's circle generator
            why not divide the circle generation further?
    2D Geometric Transformation
        translate
        scale
        rotate
        concatenation to build more sophisticated transformations
    Window vs Viewport
        window to viewport transformation
    line clipping
        Cohen-Sutherland Algorithm
    representation of area
        bitmap approach
        polygons
        polygon filling algorithm
        filling a closed contour (flood fill and boundary fill)
    clipping a hollow polygon
    clipping a filled polygon
    geometric tables (2D and 3D)
        use to prevent redundant computation
        edge for displaying image, vertex for transformations
    3D visualizations
        parallel projection
        x,y plane from the 3D coordinates
        intensity queueing, stereoscopic views, kinetic, perspective projection

format for homework:
    datalines: 4 integers separated by spaces
        n datalines
    x₀ y₀ x₁ y₁

    ex (triangle):
        10 10 5 5
        5 5 15 5
        15 5 10 10

        (read from a file, say how many lines read)

    clip lines against a viewing area
    test bresenham first


Wed Oct  5 07:59:43 EDT 2016
----------------------------



                         _.-`|P(Xe,Ye,Ze)
           P'(Xs,Ys) _.-`    |
                _.-`|        |
            _.-`    |S       |
       eye A________|B_______|C

           |----D---|

Monitor Distance
    every monitor is designed to be viewed at a distance D
        if we increase D, the size of objects on the monitor will increase to
            map to the same image size for the distance
        to the eye, there will be no difference

3D Clipping
    we form a pyramid between the eye and the viewing screen
        four lines from the eye to the tangents at each corner of the screen
    everything outside the pyramid is not visible


Thu Oct  6 08:04:27 EDT 2016
----------------------------


3D Clipping
    SEE FIG 1.1
    a point is inside the viewing pyramid if:
        -Ze <= (D/s)Xe <= Ze
        and
        -Ze <= (D/s)Ye <= Ze
    if this is true for both points, a line is visible
        apply the Cohen-Sutherland algorithm to viewport

Clipping Coordinate System
    [ Xc Yc Zc 1 ] = [ Xe Ye Ze 1 ][ N ]
        where:
                [ D/s 0   0   0 ]
            N = [ 0   D/s 0   0 ]
                [ 0   0   1   0 ]
                [ 0   0   0   1 ]
    equivalently:
        Xc = Xe + D/s
        Yc = Ye + D/s
        Ze = Ze

    conditions for clipping using the clipping coordinate system:
        (-Zc <= Xc <= Zc) and (-Zc <= Yc <= Zc)

    -------------- _
    |            | |
    |            | |
    |            | 2Vsy
    |            | |
    |            | _
    -------------- 
    |----2Vsx----|

    Xs = (Xc/Zc) * Vsx + Vcx
    Ys = (Yc/Zc) * Vsy + Vcy

Cohen-Sutherland Algorithm for 3D clipping
    as before, each of the nine regions has a 4-bit code, Cx
        (bit 1 is the least significant bit, i.e. ___x)
        set bit 1 if Xc is to the left of the pyramid
            Xc < -Zc
        set bit 2 if Xc is to the right of the pyramid
            Xc > Zc
        set bit 3 if Xc is to the left of the pyramid
            Yc < -Zc
        set bit 4 if Xc is to the right of the pyramid
            Yc > Zc
    if:    C₀ OR  C₁ == 0000 the line is visible
    elif:  C₀ AND C₁ != 0000 the line is invisible
    else:  line is potentially viaible
            compute the intersection of the line with the surface of the
                pyramid (plane)
            make two line segments, test each segment independently
            if one of the segments is visible, you do not need to test the
                other segment


Tue Oct 11 08:09:18 EDT 2016
----------------------------


Recap Summary
    1. convert image from WCS to ECS
        [ Xe Ye Ze 1 ] = [ Xw Yw Zw 1 ] [V]
            V is the viewing transformation
    2. convert to the CCS
        [ Xc Yc Zc 1 ] = [ Xe Ye Ze 1 ] [N]
            a point is visible if: (-Zc <= Xc <= Zc) and (-Zc <= Yc <= Zc)
    3. calculate Xs and Ys
        Xs = (Xc/Zc) * Vsx + Vcx
        Ys = (Yc/Zc) * Vsy + Vcy

The Viewing Transformation
    move the WCS to the center of the ECS
    rotate and flip the WCS until WCS and ECS are superimposed on each other
        we always assume that the Xe axis lies on the Z plane we are working with

    steps to find V:
        1. Translate

    ex:
        consider a cube defined in the WCS by the lines: 
            AB, BC, CD, DA, EF, FG, GH, HE, AE, BF, CG, DH
        the coordinates of these lines are:
              | Xw | Yw | Zw
            ------------
            A | -1 |  1 | -1        A_________B
            B |  1 |  1 | -1        /|       /|
            C |  1 | -1 | -1      E/_|_____F/ |
            D | -1 | -1 | -1       | |      | |
            E | -1 |  1 |  1       | |______|_| 
            F |  1 |  1 |  1       |/D      |/ C
            G |  1 | -1 |  1       |________|
            H | -1 | -1 |  1      H         G

        we will observe this cube from a point (6,8,7.5) with the viewing axis
            Ze pointed at the origin of the WCS
        we assume that Xe axis lies on the Z = 7.5 plane
            this is the general case, we always assume that the Xe axis lies on
                the Z plane we are working with

        step 1: Translate
                [ 1   0   0    0 ]
         T₁ =   [ 0   1   0    0 ]
                [ 0   0   1    0 ]
                [-6  -8  -7.5  1 ]
                (-Xe -Ye -Ze)

        step 2: Rotate
                [ 1  0  0  0 ]
          T₂ =  [ 0  0 -1  0 ]
                [ 0  1  0  0 ]
                [ 0  0  0  1 ]

            this rotation matrix is a constant (never will be different)

        step 3: Rotate about Y axis
                [ -.8   0   .6   0 ]
          T₃ =  [   0   1    0   0 ]
                [ -.6   0  -.8   0 ]
                [   0   0    0   1 ]

            this comes from:
                    [ -cosθ    0   sinθ    0 ]
                    [     0    1      0    0 ]
                    [ -sinθ    0  -cosθ    0 ]
                    [     0    0      0    1 ]

            periodic functions here are calculated as:
                sinθ = x/(sqrt(x²+y²))
                cosθ = y/(sqrt(x²+y²))
                    we can do this because it is based on triangles
        
        step 4:
                [ 1   0   0   0 ]
          T₄ =  [ 0  .8  .6   0 ]
                [ 0 -.6  .8   0 ]
                [ 0   0   0   1 ]

            it is a coincidence that these numbers are the same as in step 3

            this matrix come from:
                    [ 1     0     0    0 ]
                    [ 0  cosθ  sinθ    0 ]
                    [ 0 -sinθ  cosθ    0 ]
                    [ 0     0     0    1 ]


            periodic functions here are calculated as:
                sinθ =           z/sqrt(z²+(sqrt(x²+y²)²)
                sinθ = sqrt(x²+y²)/sqrt(z²+(sqrt(x²+y²)²)
        
        step 5: flip the Z axis

                [ 1  0  0  0 ]
           T₅ = [ 0  1  0  0 ]
                [ 0  0 -1  0 ]
                [ 0  0  0  1 ]

            this matrix is constant

        V  = T₁ * T₂ * T ₃ * T₄ * T₅
        VN = T₁ * T₂ * T ₃ * T₄ * T₅ * N


Wed Oct 12 08:04:51 EDT 2016
----------------------------


Viewing Transformation
    [V] translates the WCS to ECS
    
    ex: (same cube from yesterday)
        assume that your VP is 1024 px
        then Vcx = Vcy = Vsy = Vsx = 1023/2
        D = 60
        S = 15

            [ 4 0 0 0 ]
        N = [ 0 4 0 0 ]
            [ 0 0 1 0 ]
            [ 0 0 0 1 ]

            [ -3.2 -1.4 -.5   0 ]
        VN =[  2.4 -1.9 -.6   0 ]
            [    0  3.2 -.6   0 ]
            [    0  0    12.5 1 ]

        [ Xc Yc Zc 1 ] = [ Xw Yw Zw 1 ] * [VN]


        visible if (-Zc <= Xc <= Zc) and (-Zc <= Yc <= Zc):
            all of these are visible

        Xs = (Xc/Zc) * Vsx + Vcx
        Ys = (Yc/Zc) * Vsy + Vcy

          | Xc   | Yc   | Zc   | Xs  | Ys
          -------------------------------
        A |  5.6 | -3.7 | 12.9 | 733 | 366
        B |  -.8 | -6.6 | 12.0 | 477 | 231
        C | -5.6 | -2.7 | 13.3 | 296 | 407
        D |   .8 |   .2 | 14.2 | 540 | 517
        E |  5.6 |  2.7 | 11.7 | 755 | 630
        F |  -.8 |  -.2 | 10.8 | 474 | 504
        G | -5.6 |  3.7 | 12.1 | 274 | 668
        H |   .8 |  6.6 | 13.0 | 543 | 769

Note on 3D clipping
    3D clipping can be accomplished in the following way:
        calculate the table above
        do 2D clipping for Xs, Ys
    this causes redundant computations


Thu Oct 13 08:04:00 EDT 2016
----------------------------


Homework: search for applications of fractals

Fractals
    applications in graphics:
        generating systems like forests, bear fur, etc
    fractal is short for "fractional dimension"
    fractals look the same as we zoom in
        we can not measure fractals with a definite length
    fractals are not considered to be two dimensional
        they have a "fractional dimension"

Simple Fractal
    most sophisticated fractals come from one simple fractal
        this is referred to as the koch curve
    order 0:
       ______________________________
    order 1:
               /\          /\
              /  \        /  \
       ______/    \______/    \______ 
    order 2:
             __/\__      __/\__
             \    /      \    /
       ______/    \______/    \______ 

    ...

    to implement:
        take the first line, divide into three equal parts
        make a triangle
        repeat
    this can be done with boxes as well

Computing Dimensions
    for one dimensional entities:

        _____|_____|_____
        similarity relation = 1/3, or r = 1/3 in graphics
        1 = 3 * (1/3)^D
        so D = 1
        we can conclude from this that this entity has one dimension

    for two dimensional entities:
         _____
        |_|_|_|
        |_|_|_|
        |_|_|_|
        r = 1/3
        1 = 9 * (1/3)^D
        so D = 2
        we can conclude from this that this entity has two dimensions

    for three dimensional entities:
           ______
          /_/_/_/|
         /_/_/_/||
        /_/_/_/|/|
        |_|_|_|/|/
        |_|_|_||/
        |_|_|_|/

        imagine this is a 3x3x3 cube
        r = 1/3
        1 = 27*(1/3)^D
        D = 3

    for fractals:
             __/\__      __/\__
             \    /      \    /
       ______/    \______/    \______ 

       r = 1/3
       1 = 4 * (1/3)^D
       D = log(4)/log(3) ~= 1.2857
       we conclude that this is a 1.2857... dimensional entity
